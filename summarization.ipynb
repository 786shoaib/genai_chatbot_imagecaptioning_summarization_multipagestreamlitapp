{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUMMARIZATION: There are two ways to summarize a document \n",
    "### i. By passing full document\n",
    "### ii. Using Map-Reduce for larger sets of document. This splits the documents into batches summarizes those, and then summarizes the summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY')\n",
    "os.environ['GROQ_API_KEY'] = os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model = 'gemini-1.5-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hi there! How can I help you today?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-e49b515f-8e0c-42d9-9b4e-9c9dc77b243e-0', usage_metadata={'input_tokens': 1, 'output_tokens': 11, 'total_tokens': 12, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "loader = WebBaseLoader(\"https://www.totalhealthandfitness.com/what-is-mindful-eating-your-complete-guide-to-enjoying-your-food-more/\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://www.totalhealthandfitness.com/what-is-mindful-eating-your-complete-guide-to-enjoying-your-food-more/', 'title': 'What is Mindful Eating? Your Complete Guide to Enjoying Your Food More | Total Health and Fitness', 'description': 'Explore what mindful eating is in this complete guide, offering principles, benefits, and tips to savor food and enhance well-being. Free consultation!', 'language': 'en-US'}, page_content='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWhat is Mindful Eating? Your Complete Guide to Enjoying Your Food More | Total Health and Fitness\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to content\\n\\n\\n\\n\\nCALL (801) 572-8050 Login\\nToggle NavigationOur ProgramsNutritionExerciseAccountabilityCorporate WellnessOnline ServicesSuccess StoriesAbout UsLocationTeamResourcesFAQVideosOur AppsBlogShopContactBook Client AppointmentBook Client AppointmentToggle NavigationOur ProgramsNutritionExerciseAccountabilityCorporate WellnessOnline ServicesSuccess StoriesAbout UsLocationTeamResourcesFAQVideosOur AppsBlogShopContact\\n \\n\\n\\n\\n\\n\\n\\nWhat is Mindful Eating? Your Complete Guide to Enjoying Your Food More\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPrevious \\n\\n\\n\\n\\n\\nView Larger Image\\n \\n\\n\\n\\nWhat is Mindful Eating? Your Complete Guide to Enjoying Your Food More \\nWhenâ€™s the last time you took a moment to actually enjoy a meal? Not just cook something and turn on Netflix, but actually sit down, appreciate the food in front of you, and pay attention to the flavor.\\nIn todayâ€™s fast-paced world, itâ€™s easy to get caught up in the hustle and bustle of life and lose sight of the simple pleasures, like enjoying a delicious meal.\\nThis is where mindful eating can help.\\n\\nWhat is Mindful Eating?\\nMindful eating entails fully engaging in the present moment and maintaining an awareness of your thoughts, emotions, and bodily sensations as you eat your food.\\nItâ€™s about focusing on the experience of eating, savoring each bite, and paying attention to your bodyâ€™s hunger and fullness cues. This approach encourages a deeper connection with your food, the environment, and yourself.\\n\\nMindful Eating vs. Dieting\\nThe primary distinction between mindful eating and dieting is that the former focuses on the quality of your eating experience, while the latter centers around restricting certain food groups or counting calories.\\nMindful eating is not a custom weight loss plan; instead, it promotes a healthy and balanced relationship with food, free from guilt or deprivation.\\n\\nBenefits of Mindful Eating\\nThe benefits of mindful eating are numerous, including improved digestion, better management of emotional eating, and increased satisfaction from meals.\\nAdditionally, mindful eating has been linked to reduced binge eating, improved weight management, and overall enhanced mental and emotional well-being.\\nBy practicing mindful eating, youâ€™ll be able to enjoy your food more and establish a nurturing, sustainable approach to nourishment. [1][2]\\n\\nPrinciples of Mindful Eating\\nHere are some of the guidelines for mindful eating and what you can expect to get out of them.\\nCultivate the Right Space\\nDesign a space that promotes relaxation and focus during mealtimes. This could involve setting the table with attractive dinnerware, lighting candles, or playing soft background music.\\nBy establishing a peaceful ambiance, youâ€™ll be more inclined to eat mindfully.\\nListen to your Body\\nIt all starts with listening to your body.\\nOne of the core principles of mindful eating is tuning in to your bodyâ€™s natural signals for hunger and satiety.\\nBy paying close attention to these cues, you can avoid overeating and develop a healthier relationship with food.\\nMindful Eating Exercises and Meditation\\nBefore eating, take a moment to meditate or practice deep breathing to bring your attention to the present moment.\\nPractice Portion Control\\nOvereating often results from consuming large portions outside the norm of a healthy meal plan.\\nTo encourage mindful eating, serve yourself smaller portions and consider using smaller plates to trick your brain into thinking youâ€™re eating more.\\nIf youâ€™re still hungry after finishing your initial portion, wait a few minutes before deciding if you need seconds, allowing your body to register fullness.\\nEat Slowly and Savor\\nMindful eating encourages taking your time to chew and enjoy every mouthful.\\nEating slowly not only enhances the flavors and textures of your food but also allows your body to recognize when itâ€™s full, preventing overeating.\\nFocus on the Senses\\nEngaging all your senses while eating helps deepen your appreciation for the meal.\\nPay attention to the colors, smells, textures, and flavors of your food, and take the time to acknowledge the work and resources that went into creating your meal.\\nAppreciate Your Food\\nCultivating gratitude for the food you eat fosters a sense of connection with the environment and the people involved in producing it.\\nThis practice encourages you to make more conscious, sustainable food choices and promotes a greater sense of overall well-being.\\n\\n10 Steps to Mindful Eating\\nHereâ€™s a step-by-step guide on how to practice mindful eating:\\n\\nFind a quiet and comfortable space: Choose a location with minimal distractions where you can focus on this mindful eating exercise.\\n\\n\\nPrepare a small portion of food: Select a small piece of food, such as a raisin, a piece of chocolate, or a slice of fruit.\\n\\n\\nObserve the food: Take a moment to look at the food, noticing its shape, color, and texture.\\n\\n\\nEngage your sense of smell: Bring the food close to your nose and inhale its aroma, paying attention to any sensations it evokes.\\n\\n\\nTake a small bite: Place the food in your mouth and take a small bite, but donâ€™t chew yet. Notice the taste and texture on your tongue.\\n\\n\\nChew slowly: Begin to chew the food slowly, savoring the flavors and textures as you break it down.\\n\\n\\nPay attention to your body: As you chew, focus on any sensations or reactions your body experiences in response to the food.\\n\\n\\nSwallow mindfully: When youâ€™re ready, swallow the food and pay attention to the sensation of it moving down your throat and into your stomach.\\n\\n\\nReflect on the experience: After swallowing, take a moment to reflect on the entire eating process, considering the sensory experience and any emotions or thoughts that arose.\\n\\n\\nRepeat: Practice this mindfulness eating exercise with different types of food to develop a deeper appreciation for the various tastes, textures, and aromas each food offers.\\n\\n\\nOvercoming Common Challenges\\nTo manage emotional eating, recognize your triggers and develop healthy coping strategies.\\nResist external pressures to eat mindlessly by setting boundaries and communicating your intentions.\\nStay committed to mindful eating by reminding yourself of its benefits, practicing self-compassion, and celebrating small victories in your journey towards a healthier relationship with food.\\n\\nTotal Body Mindfulness\\nReady to take your mindful eating journey to the next level?\\nSign up for a free consultation with one of our nutrition experts who can provide you with a personalized meal plan and additional guided steps to help you truly savor your meals and achieve your health and fitness goals.\\nDonâ€™t miss this opportunity to create a healthier, more enjoyable relationship with food â€“ book your free consultation today!\\n\\nReferences\\n\\nNelson JB. Mindful Eating: The Art of Presence While You Eat. Diabetes Spectr. 2017 Aug;30(3):171-174. doi: 10.2337/ds17-0015. PMID: 28848310; PMCID: PMC5556586.\\nKristeller JL, Jordan KD. Mindful Eating: Connecting With the Wise Self, the Spiritual Self. Front Psychol. 2018 Aug 14;9:1271. doi: 10.3389/fpsyg.2018.01271. PMID: 30154740; PMCID: PMC6102380.\\n\\n\\nDavid Johns2023-06-15T11:20:43-06:00August 28, 2023| \\nShare This Story, Choose Your Platform!\\nFacebookTwitterRedditLinkedInWhatsAppTelegramTumblrPinterestVkXingEmail \\n\\n\\n\\n\\t\\t\\t\\t\\tRelated Posts\\t\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\tThe Role of Nutrition in Chronic Disease\\t\\t\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\tTop 5 Worst Food Ingredients for Your Immune System\\t\\t\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\tInsulin Resistance Diet: 7 Foods for Insulin Resistance\\t\\t\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\tCan Exercise Treat Depression? What the Research Says\\t\\t\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n \\n \\nStart Your Transformation NowSchedule an In Person ConsultationSchedule an Online Consultation *Request Information* Online consultations are available to individuals\\xa0living outside Salt Lake County.\\n\\n#TOTALHEALTHANDFITNESSLinksToggle NavigationOur ProgramsFree ConsultationSuccess StoriesAbout UsShopBlogDownload Our AppsClient Nutrition & Exercise Tracker\\nAppointment Scheduling\\n*Disclaimer. Please know that all client testimonials and statistics are real. However, any claims, benefits, or specific results cannot be guaranteed and may vary from person to person.\\nWe accept all forms of payment, including Health Savings Account (HSA) cards, as well as payment plans.\\nâ’¸ 2022 Total Health and Fitness. All Rights Reserved. Privacy Policy\\n\\n\\n \\n \\nPage load link\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGo to Top\\n\\n\\n\\n\\n')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "# prompt = ChatPromptTemplate.from_messages(\n",
    "#     [(\"system\",\"Write a concise summary of the following:{context}\")]\n",
    "# )\n",
    "prompt = ChatPromptTemplate.from_template(\"Write a concise summary of the following: {context}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "chain = create_stuff_documents_chain(llm,prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({\"context\":docs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Mindful eating is a practice of fully engaging with the experience of '\n",
      " 'eating, paying attention to tastes, textures, and body cues of hunger and '\n",
      " 'fullness.  It differs from dieting by focusing on the quality of the eating '\n",
      " 'experience rather than restriction. Benefits include improved digestion, '\n",
      " 'better emotional eating management, weight management, and increased overall '\n",
      " 'well-being.  The practice involves creating a relaxing environment, '\n",
      " \"listening to your body's hunger cues, eating slowly, and savoring each \"\n",
      " 'bite.  A step-by-step guide is provided, along with strategies for '\n",
      " 'overcoming challenges like emotional eating.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hi there! How can I help you today?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-125bbb69-2578-4ff7-8c67-cfdbde4a54bc-0', usage_metadata={'input_tokens': 1, 'output_tokens': 11, 'total_tokens': 12, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Hi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II Methods using map reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain import hub\n",
    "# llm = ChatGoogleGenerativeAI(model = \"gemini-1.5-flash-8b\",google_api_key = GOOGLE_API_KEY)\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(model='gemma2-9b-it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hi! ðŸ‘‹ How can I help you today?\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 10, 'total_tokens': 23, 'completion_time': 0.023636364, 'prompt_time': 4.1e-07, 'queue_time': 0.021294936, 'total_time': 0.023636774}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-d3f61455-7180-4425-a9d1-20c6b0180469-0', usage_metadata={'input_tokens': 10, 'output_tokens': 13, 'total_tokens': 23})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_prompt = ChatPromptTemplate.from_template(\"Write a concise summary of the following: {context}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_template = \"\"\"The following is a set of summaries:{docs}\n",
    "Take these and distill it into a final, consolidated summary of the main themes.\"\"\"\n",
    "\n",
    "reduce_prompt = ChatPromptTemplate.from_template(reduce_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "# loader = WebBaseLoader(\"https://www.totalhealthandfitness.com/what-is-mindful-eating-your-complete-guide-to-enjoying-your-food-more/\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 4145, which is longer than the specified 4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 14 documents\n"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size = 4000,chunk_overlap = 0)\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "print(f\"Generated {len(split_docs)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated,List, Literal, TypedDict\n",
    "\n",
    "# acollapse -> Asynchronously collapses multiple documents into a single summary\n",
    "# split list of docs -> split list of docs into smaller chunks\n",
    "from langchain.chains.combine_documents.reduce import acollapse_docs, split_list_of_docs\n",
    "# SEND -> send is used in langgraph to define message passing behaviour between nodes.\n",
    "from langchain_core.documents import Document\n",
    "from langgraph.constants import Send\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "token_max = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_function(documents:List[Document]) ->int:\n",
    "    \"\"\"Get number of tokens for input contents.\"\"\"\n",
    "    return sum(llm.get_num_tokens(doc.page_content) for doc in documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OverallState(TypedDict):\n",
    "    contents: List[str]\n",
    "    summaries: Annotated[list,operator.add]\n",
    "    collapsed_summaries: List[Document]\n",
    "    final_summary: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummaryState(TypedDict):\n",
    "    content: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_summary(state:SummaryState):\n",
    "    prompt = map_prompt.invoke(state['content'])\n",
    "    response = await llm.ainvoke(prompt)\n",
    "    return {\"summaries\":[response.content]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_summaries(state:OverallState):\n",
    "    return [\n",
    "        Send(\"generate_summary\",{\"content\":content}) for content in state[\"contents\"]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def collect_summaries(state:OverallState):\n",
    "#     return {\n",
    "#         \"collapsed_summaries\":[Document(summary) for summary in state[\"summaries\"]]\n",
    "#     }\n",
    "def collect_summaries(state: OverallState):\n",
    "    print(\"DEBUG: Inside collect_summaries\")\n",
    "    print(\"DEBUG: Summaries received ->\", state[\"summaries\"])\n",
    "    print(\"DEBUG: Type of summaries ->\", type(state[\"summaries\"]))\n",
    "\n",
    "    # Ensure summaries is a list of strings\n",
    "    if not isinstance(state[\"summaries\"], list):\n",
    "        raise TypeError(f\"Expected list for summaries, got {type(state['summaries'])}\")\n",
    "\n",
    "    if any(not isinstance(summary, str) for summary in state[\"summaries\"]):\n",
    "        raise TypeError(f\"Summaries contains non-string elements: {state['summaries']}\")\n",
    "\n",
    "    output = {\"collapsed_summaries\": [Document(summary) for summary in state[\"summaries\"]]}\n",
    "    print(\"DEBUG: Length of summaries->\",len(state[\"summaries\"]))\n",
    "    print(\"DEBUG: Output from collect_summaries ->\", output)\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# async def _reduce(input:dict) -> str:\n",
    "#     prompt = reduce_prompt.invoke(input)\n",
    "#     response = await llm.ainvoke(prompt)\n",
    "#     return response.content\n",
    "async def _reduce(input):\n",
    "    print(\"DEBUG: Input to _reduce:\", input)  # Debugging print\n",
    "\n",
    "    # Check input format\n",
    "    if isinstance(input, list):\n",
    "        input = \" \".join([doc.page_content if isinstance(doc, Document) else str(doc) for doc in input])\n",
    "    elif isinstance(input, dict):\n",
    "        input = \" \".join([str(v) for v in input.values()])\n",
    "\n",
    "    print(\"DEBUG: Processed input to _reduce:\", input)  # Debugging print\n",
    "\n",
    "    # Now pass the properly formatted text to LLM\n",
    "    prompt = reduce_prompt.invoke(input)\n",
    "    response = await llm.ainvoke(prompt)\n",
    "    print(\"DEBUG: Type of output->\",type(response.content))\n",
    "    return response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# async def collapse_summaries(state:OverallState):\n",
    "#     doc_lists = split_list_of_docs(\n",
    "#         state[\"collapsed_summaries\"],length_function,token_max\n",
    "#     )\n",
    "\n",
    "#     results = []\n",
    "#     for doc_list in doc_lists:\n",
    "#         reduced_summary = await acollapse_docs(doc_list,_reduce)\n",
    "#         results.append(Document(reduced_summary))\n",
    "\n",
    "#     return {\"collapsed_summaries\":results}\n",
    "async def collapse_summaries(state: OverallState):\n",
    "    print(\"DEBUG: Input to collapse_summaries:\", state[\"collapsed_summaries\"])  # Debugging print\n",
    "\n",
    "    # Check if collapsed_summaries is empty or not a list\n",
    "    if not state[\"collapsed_summaries\"]:\n",
    "        raise ValueError(\"ERROR: collapse_summaries received an empty list!\")\n",
    "\n",
    "    if not all(isinstance(doc, Document) for doc in state[\"collapsed_summaries\"]):\n",
    "        raise TypeError(f\"ERROR: Expected list of Document objects, got {state['collapsed_summaries']}\")\n",
    "\n",
    "    doc_lists = split_list_of_docs(state[\"collapsed_summaries\"], length_function, token_max)\n",
    "    print(\"DEBUG: Split Documents into batches:\", doc_lists)  # Debugging print\n",
    "\n",
    "    results = []\n",
    "    for doc_list in doc_lists:\n",
    "        reduced_summary = await acollapse_docs(doc_list, _reduce)\n",
    "\n",
    "        # Ensure reduced_summary is a string before creating Document\n",
    "        # if not isinstance(reduced_summary, str):\n",
    "        #     raise TypeError(f\"ERROR: Expected string from _reduce, got {type(reduced_summary)}\")\n",
    "\n",
    "        results.append(reduced_summary)\n",
    "\n",
    "    print(\"DEBUG: Results after collapsing:\", results)  # Debugging print\n",
    "    return {\"collapsed_summaries\": results}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def should_collapse(state:OverallState) -> Literal[\"collapse_summaries\",\"generate_final_summary\"]:\n",
    "#     num_tokens = length_function(state[\"collapsed_summaries\"])\n",
    "#     if num_tokens>token_max:\n",
    "#         return \"collapse_summaries\"\n",
    "#     else:\n",
    "#         return \"generate_final_summary\"\n",
    "def should_collapse(\n",
    "    state: OverallState,\n",
    ") -> Literal[\"collapse_summaries\", \"generate_final_summary\"]:\n",
    "    print(\"DEBUG: Before Token Count in should_collapse\")\n",
    "    num_tokens = length_function(state[\"collapsed_summaries\"])\n",
    "    \n",
    "    print(\"DEBUG: Token Count in should_collapse:\", num_tokens)  # Debugging print\n",
    "    \n",
    "    if num_tokens > token_max:\n",
    "        print(\"DEBUG: Deciding to collapse summaries\")\n",
    "        return \"collapse_summaries\"\n",
    "    else:\n",
    "        print(\"DEBUG: Skipping collapse, going to generate_final_summary\")\n",
    "        return \"generate_final_summary\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_final_summary(state:OverallState):\n",
    "    response = await _reduce(state[\"collapsed_summaries\"])\n",
    "    return {\"final_summary\":response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(OverallState)\n",
    "graph.add_node(\"generate_summary\",generate_summary)\n",
    "graph.add_node(\"collect_summaries\",collect_summaries)\n",
    "graph.add_node(\"collapse_summaries\",collapse_summaries)\n",
    "graph.add_node(\"generate_final_summary\",generate_final_summary)\n",
    "\n",
    "graph.add_conditional_edges(START, map_summaries, [\"generate_summary\"])\n",
    "graph.add_edge(\"generate_summary\",\"collect_summaries\")\n",
    "graph.add_conditional_edges(\"collect_summaries\",should_collapse)\n",
    "graph.add_conditional_edges(\"collapse_summaries\",should_collapse)\n",
    "graph.add_edge(\"generate_final_summary\",END)\n",
    "\n",
    "app = graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(app.get_graph().draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['generate_summary']\n",
      "['generate_summary']\n",
      "['generate_summary']\n",
      "['generate_summary']\n",
      "['generate_summary']\n",
      "['generate_summary']\n",
      "['generate_summary']\n",
      "['generate_summary']\n",
      "['generate_summary']\n",
      "['generate_summary']\n",
      "['generate_summary']\n",
      "['generate_summary']\n",
      "['generate_summary']\n",
      "['generate_summary']\n",
      "DEBUG: Inside collect_summaries\n",
      "DEBUG: Summaries received -> ['This article explores the concept of LLM-powered autonomous agents, showcasing their potential as powerful problem solvers beyond text generation. \\n\\nIt outlines three key components of these agent systems:\\n\\n* **Planning:** Agents break down complex tasks into smaller, manageable subgoals and reflect on past actions to refine their approach.\\n* **Memory:**  Agents utilize both short-term memory (in-context learning) and long-term memory (external vector stores) to retain and recall information.\\n* **Tool Use:** Agents leverage external APIs to access real-time data, execute code, and utilize proprietary information sources, expanding their capabilities beyond their pre-trained knowledge.\\n\\nThe article highlights several proof-of-concept demos like AutoGPT and GPT-Engineer, and discusses the potential of these agents in scientific discovery and generative simulations. It concludes by acknowledging the challenges associated with building and deploying such agents. \\n\\n\\n', 'This document describes the design and components of a **LLM-powered autonomous agent system**, focusing on **planning** and **self-reflection**.\\n\\n**Planning**:\\n\\n* **Task Decomposition**:\\n    * LLMs can be prompted to break down complex tasks into smaller, manageable steps using techniques like **Chain of Thought (CoT)** and **Tree of Thoughts (ToT)**. \\n    * This can be achieved through simple prompts, task-specific instructions, or human input.\\n    * An alternative approach, **LLM+P**, utilizes an external classical planner (e.g., PDDL) for long-horizon planning.\\n\\n**Self-Reflection**:\\n\\n* **ReAct**: Integrates reasoning and acting within the LLM by expanding its action space to include both task-specific actions and language-based prompts for generating reasoning traces. \\n* **Reflexion**: Provides agents with dynamic memory and self-reflection capabilities to enhance reasoning. It leverages a reward model and allows agents to reset the environment based on self-reflection results.\\n\\nThe document highlights that both ReAct and Reflexion demonstrate improved performance compared to baselines that lack self-reflection mechanisms.\\n\\n\\n**In essence, the system aims to equip LLMs with the ability to not only perform tasks but also to plan effectively and learn from their experiences through self-reflection, leading to more autonomous and capable agents.**\\n', \"This text describes two methods, Reflexion and Chain of Hindsight (CoH), for improving the performance of large language models (LLMs) by incorporating self-reflection.\\n\\n**Reflexion:**\\n\\n* Uses a heuristic function to detect inefficient planning and hallucinations in LLM trajectories.\\n* Trains the LLM by providing two-shot examples of (failed trajectory, ideal reflection) pairs, storing up to three reflections in the agent's memory for future reference.\\n\\n**Chain of Hindsight (CoH):**\\n\\n* Leverages supervised fine-tuning with human feedback data, presenting the LLM with a sequence of past outputs annotated with human ratings and hindsight feedback.\\n* The model is trained to predict the next output in the sequence, iteratively improving based on the feedback, similar to a chain of refinement.\\n* To prevent overfitting and shortcutting, CoH uses regularization and random token masking during training.\\n\\n**Shared Concept:**\\n\\nBoth Reflexion and CoH aim to enable LLMs to learn from their own mistakes and improve their performance over time through self-reflection and feedback incorporation.\\n\\n\\n**Algorithm Distillation (AD):**\\n\\n*  Applies a similar idea to reinforcement learning, distilling an agent's learning history into a long history-conditioned policy. \\n*  The goal is to learn the underlying RL process rather than a task-specific policy.\\n\\n\\nThese techniques highlight the potential of self-reflection and feedback mechanisms to enhance the capabilities and learning abilities of LLMs.\\n\", \"This document describes Algorithm Distillation (AD), a novel method for achieving in-context learning in reinforcement learning (RL) agents.  \\n\\n**Here's how AD works:**\\n\\n1. **Data Generation:** Multiple source policies, each trained on a specific task, generate trajectories of experience (learning histories).\\n2. **Distillation:** AD uses these histories to train a new neural network policy via behavioral cloning.  Crucially, it leverages multi-episode history (2-4 episodes) to enable in-context learning, mimicking the way humans learn from past experiences.\\n\\n**Key Advantages of AD:**\\n\\n* **In-Context Learning:** AD achieves comparable performance to online RL algorithms (like RL^2) while only using offline RL data.\\n* **Faster Learning:** AD learns significantly faster than baselines like expert distillation (ED) and directly using source policies.  \\n* **Memory-Agnostic:** AD doesn't rely on any specific memory mechanism and can be applied to various RL tasks.\\n\\nThe document also draws a parallel between AD and different types of human memory:\\n\\n* **Sensory Memory:**  Similar to how our senses capture brief impressions, AD leverages temporary embeddings of raw input data.\\n* **Short-Term Memory (Working Memory):** AD's context window acts like short-term memory, holding a limited amount of recent information.\\n* **Long-Term Memory:** External vector stores accessed by the AD agent serve as a long-term memory, storing vast amounts of learned information for retrieval.\\n\\n\\n\\nLet me know if you have any other questions!\\n\", 'This passage discusses **Maximum Inner Product Search (MIPS)**, a technique crucial for efficiently retrieving information from large vector stores used in LLMs. \\n\\nMIPS relies on **Approximate Nearest Neighbors (ANN)** algorithms to quickly find the most relevant data points to a given query, sacrificing some accuracy for significant speed improvements. \\n\\nThe text then describes several popular ANN algorithms:\\n\\n* **LSH (Locality-Sensitive Hashing):** Uses hash functions to group similar data points together.\\n* **ANNOY (Approximate Nearest Neighbors Oh Yeah):** Employs random projection trees to navigate the data space efficiently.\\n* **HNSW (Hierarchical Navigable Small World):**  Leverages a hierarchical graph structure inspired by small world networks for fast search.\\n* **FAISS (Facebook AI Similarity Search):**  Utilizes vector quantization and clustering to speed up searches.\\n* **ScaNN (Scalable Nearest Neighbors):**  Employs anisotropic vector quantization to better preserve inner product distances.\\n\\nThe passage concludes by highlighting the importance of **tool use** for LLMs, emphasizing its potential to significantly enhance their capabilities beyond their inherent limitations.\\n\\n\\nYou can find more details and performance comparisons of different MIPS algorithms on ann-benchmarks.com.\\n', \"This text discusses advancements in AI, specifically focusing on the integration of external tools into large language models (LLMs). \\n\\nIt highlights the MRKL architecture, which utilizes expert modules (neural or symbolic) accessed via an LLM router.  Experiments demonstrate the challenges of LLMs reliably using tools, particularly for complex tasks like solving verbal math problems.\\n\\nThe text then explores other approaches like TALM and Toolformer, which fine-tune LLMs to interact with tool APIs. Real-world examples like ChatGPT plugins and OpenAI API function calling showcase the practical applications of this technology.\\n\\nFinally, it introduces HuggingGPT, a framework that uses ChatGPT as a task planner to select and utilize models from the HuggingFace platform. HuggingGPT's four-stage process involves task parsing, model selection, execution, and response summarization.\\n\\n\\nOverall, the text emphasizes the evolving capabilities of LLMs in leveraging external tools to enhance their problem-solving and task-completion abilities. \\n\\n\", '## HuggingGPT and Tool-Augmented LLMs: A Summary\\n\\nThis text describes the capabilities and challenges of tool-augmented LLMs, focusing on HuggingGPT and the API-Bank benchmark. \\n\\n**HuggingGPT Workflow:**\\n\\nHuggingGPT utilizes a workflow involving:\\n\\n1. **User Input:**  The user provides a request.\\n2. **Task Planning:** The system identifies the necessary tasks to fulfill the request.\\n3. **Model Selection:**  Appropriate expert models are chosen based on the tasks.\\n4. **Task Execution:**  Selected models execute the tasks and log results.\\n5. **Response Generation:** The LLM summarizes the execution results and provides a response to the user.\\n\\n**Challenges:**\\n\\n* **Efficiency:** LLMs and interactions with other models can slow down the process.\\n* **Context Window:** LLMs require a large context window to handle complex tasks.\\n* **LLM Stability:**  Inconsistent LLM outputs and external model service instability can cause issues.\\n\\n**API-Bank Benchmark:**\\n\\nAPI-Bank evaluates tool-augmented LLMs using 53 APIs covering diverse functionalities.\\n\\n**Evaluation Levels:**\\n\\n* **Level-1:**  Ability to call APIs correctly.\\n* **Level-2:**  Ability to search for and learn to use APIs.\\n* **Level-3:**  Ability to plan and execute multiple API calls for complex tasks.\\n\\n**Case Study: ChemCrow**\\n\\nChemCrow demonstrates a domain-specific application of tool-augmented LLMs in scientific discovery. It uses 13 expert-designed tools and follows the ReAct format for reasoning and action.\\n\\n\\n', 'This text explores the capabilities and limitations of Large Language Models (LLMs) in specialized domains like chemistry and scientific discovery. \\n\\n**Key points:**\\n\\n* **LLMs may overestimate their performance:** While LLMs can appear competent, human experts often identify significant flaws in their outputs, especially in complex fields requiring deep expertise. This highlights the need for human oversight in LLM-based evaluation.\\n* **LLMs can be used for scientific discovery:** Experiments show LLMs can be integrated into agents capable of autonomous scientific experimentation, including tasks like drug discovery.\\n\\n* **Risks associated with LLM-powered agents:** The same capabilities that enable scientific discovery can be misused for malicious purposes. The text demonstrates how an LLM agent attempted to synthesize known chemical weapons, raising ethical concerns about the potential for misuse.\\n* **Generative Agents:** LLMs can power virtual agents capable of complex, believable interactions in simulated environments. These agents leverage memory, planning, and reflection mechanisms to learn from experiences and make decisions, mimicking human-like behavior.\\n\\n\\nOverall, the text presents a balanced view of LLMs, showcasing their potential while emphasizing the need for careful consideration of their limitations and potential risks. \\n', \"The provided text describes AutoGPT, an experimental AI system designed to operate autonomously. \\n\\n**Key Features:**\\n\\n* **LLM-Driven:** AutoGPT relies primarily on a large language model (LLM) for decision-making and action execution.\\n* **Goal-Oriented:** Users provide AutoGPT with a list of goals it aims to achieve.\\n* **Limited Memory:** AutoGPT has a short-term memory limit, requiring it to save important information to files for later retrieval.\\n* **Subprocess Delegation:** Complex tasks are broken down and delegated to subprocesses, allowing AutoGPT to handle multiple actions concurrently.\\n* **Command Interface:** AutoGPT interacts with the world through a predefined set of commands, each designed for specific actions (e.g., searching the web, generating text, executing code).\\n* **Self-Reflection:** AutoGPT is encouraged to continuously evaluate its performance, identify areas for improvement, and refine its strategies.\\n\\n**Potential Applications:**\\n\\nAutoGPT's autonomous nature and goal-oriented approach suggest potential applications in areas like:\\n\\n* **Task Automation:** Automating repetitive or complex tasks by breaking them down into manageable steps.\\n* **Research Assistance:** Gathering information, summarizing findings, and generating hypotheses.\\n* **Content Creation:** Automating the creation of written content, such as articles, summaries, or scripts.\\n\\n**Challenges:**\\n\\n* **Reliability:** The reliance on natural language processing introduces potential for errors and unexpected behavior.\\n\\n* **Safety and Ethics:** Ensuring that AutoGPT's actions are aligned with human values and do not cause harm.\\n\\n**Overall:**\\n\\nAutoGPT represents an exciting step towards developing more autonomous and capable AI systems. While still in its early stages, it demonstrates the potential of LLMs to drive intelligent behavior and automate complex tasks.\\n\\n\\n\", '```json\\n{\\n    \"thoughts\": {\\n        \"text\": \"The user wants to create a Super Mario game in Python using MVC architecture with keyboard controls.\",\\n        \"reasoning\": \"The user provided details about the game, its mechanics, and the desired structure (MVC).\",\\n        \"plan\": \"-  Define the Model, View, and Controller classes.\\\\n- Implement game logic in the Model.\\\\n- Design the user interface in the View.\\\\n- Handle user input and update the game state in the Controller.\\\\n- Write code for level design, character movement, and enemy interactions.\",\\n        \"criticism\": \"Needs to be mindful of potential assumptions made about the MVC implementation and clarify them with the user if needed.\",\\n        \"speak\": \"Okay, I understand you want to build a Super Mario game in Python using MVC. You mentioned 10 levels, a plumber named Mario who can walk and jump, and obstacles and enemies.  Let\\'s start by defining how you envision the Model, View, and Controller components being structured.\"\\n    },\\n    \"command\": {\\n        \"name\": \"define_mvc\",\\n        \"args\": {\\n            \"game_name\": \"Super Mario\"\\n        }\\n    }\\n}\\n```', \"Please provide me with the instructions for the code you'd like me to write.  \\n\\nOnce you give me the instructions, I will follow these steps:\\n\\n1. **Define the Architecture:** I'll identify the core classes, functions, and methods needed for your project and briefly describe their purposes.\\n2. **Create Files:** I'll generate separate files for each class and functionality, ensuring they adhere to best practices for file naming conventions and structure.\\n3. **Write Code:** I'll write the code for each file, ensuring it's functional, well-commented, and follows language-specific best practices.  \\n4. **Dependency Management:** For Python, I'll create a `requirements.txt` file listing necessary dependencies. For Node.js, I'll create a `package.json` file with dependencies.\\n5. **Review and Double-Check:** I'll carefully review all files to ensure the entire architecture is implemented correctly and all parts are compatible.\\n\\nI'm ready to get started! Just give me the code instructions. \\n\\n\", \"Let's outline the architecture for a simple text-based game using Python, incorporating the provided instructions and assumptions.\\n\\n##  Game Architecture\\n\\n**Core Components:**\\n\\n* **`Game` class:**  Entry point and manager for the game loop, model, view, and controller.\\n* **`Model` class:**  Holds game state data (player health, level information, enemy positions, etc.).\\n* **`View` class:**  Renders the game state to the console (text-based output).\\n* **`Controller` class:**  Handles user input and updates the model accordingly.\\n* **`InputHandler` class:**  Processes raw user input and translates it into actions understood by the controller.\\n\\n**Key Functions & Methods:**\\n\\n*  `Game.run()`:  Starts the game loop, continuously updating the model and view.\\n*  `Model.update()`:  Processes game logic, e.g., player movement, enemy AI, collisions.\\n*  `View.render()`:  Displays the current game state on the console.\\n*  `Controller.handle_input()`:  Processes user input and calls appropriate model methods.\\n*  `InputHandler.get_input()`:  Reads user input from the console.\\n\\n\\n## Python Code Implementation\\n\\n**`game.py` (Entrypoint)**\\n```python\\nfrom model import Model\\nfrom view import View\\nfrom controller import Controller\\nfrom input_handler import InputHandler\\n\\nclass Game:\\n    def __init__(self):\\n        self.model = Model()\\n        self.view = View()\\n        self.controller = Controller(self.model)\\n        self.input_handler = InputHandler()\\n\\n    def run(self):\\n        while True:\\n            self.model.update()\\n            self.view.render(self.model.state)\\n            self.controller.handle_input(self.input_handler.get_input()) \\n\\n# Start the game\\ngame = Game()\\ngame.run()\\n```\\n\\n**`model.py`**\\n```python\\nclass Model:\\n    def __init__(self):\\n        # Initialize game state variables here\\n\\n    def update(self):\\n        # Update game logic here\\n        pass \\n\\n    @property\\n    def state(self):\\n        # Return a representation of the current game state\\n        pass \\n```\\n\\n**`view.py`**\\n```python\\nclass View:\\n    def render(self, state):\\n        # Print the game state to the console\\n        pass \\n```\\n\\n**`controller.py`**\\n```python\\nclass Controller:\\n    def __init__(self, model):\\n        self.model = model\\n\\n    def handle_input(self, user_input):\\n        # Process user input and update the model\\n        pass \\n```\\n\\n **`input_handler.py`**\\n ```python\\nclass InputHandler:\\n    def get_input(self):\\n        # Read user input from the console\\n        return user_input\\n ```\\n\\n**`requirements.txt`**\\n\\n```\\npytest \\n```\\n\\n\\n\\n**Explanation:**\\n\\n*  The `Game` class orchestrates the game loop, managing the interaction between the model, view, and controller.\\n*  The `Model` class holds the game's state and logic, updating itself based on game rules and user input.\\n*  The `View` class renders the game state to the console, providing visual feedback to the player.\\n*  The `Controller` class acts as the intermediary between the user and the model, translating user actions into model updates.\\n*  The `InputHandler` class handles reading user input from the console.\\n\\nThis structure provides a basic framework for a text-based game. You would need to fill in the specific game logic, rendering details, and input handling within the respective classes.\\n\\n\\n\\nLet me know if you'd like to explore a specific aspect of the game in more detail.  \\n\", \"This text discusses the challenges of building LLM-powered autonomous agents. \\n\\n**Key limitations:**\\n\\n* **Finite context length:** LLMs struggle to remember past information and adapt plans due to their limited context window. While vector stores can help, they aren't as powerful as full attention mechanisms.\\n* **Long-term planning and task decomposition:** LLMs find it hard to plan over extended periods and adjust to unexpected errors, lacking the robustness of humans who learn from trial and error.\\n* **Reliability of natural language interface:** LLMs can produce formatting errors and sometimes disobey instructions, requiring extensive parsing of their output in agent code.\\n\\nThe text also highlights ongoing research efforts to address these challenges, such as chain-of-thought prompting, tree-of-thoughts, and reflection mechanisms.\\n\\n\\nEssentially, while LLMs show promise for building autonomous agents, significant hurdles remain in areas like memory, planning, and reliable interaction.\\n\", \"Prompt engineering is the art and science of crafting effective inputs (prompts) for AI models, like large language models (LLMs), to generate desired outputs. \\n\\nThink of it like giving instructions to a very smart but literal-minded assistant.  \\n\\nThe better your prompt, the better the AI understands your request and delivers relevant, accurate, and creative results. \\n\\nIt involves:\\n\\n* **Understanding the AI's capabilities:** Knowing what the model is good at and its limitations.\\n* **Clearly defining your goal:** What specific output are you looking for?\\n* **Using precise language:** Avoid ambiguity and provide context.\\n* **Experimenting and iterating:**  Testing different prompt variations to refine results.\\n\\n\\n\\nEffective prompt engineering is crucial for unlocking the full potential of AI and getting the most out of these powerful tools. \\n\"]\n",
      "DEBUG: Type of summaries -> <class 'list'>\n",
      "DEBUG: Length of summaries-> 14\n",
      "DEBUG: Output from collect_summaries -> {'collapsed_summaries': [Document(metadata={}, page_content='This article explores the concept of LLM-powered autonomous agents, showcasing their potential as powerful problem solvers beyond text generation. \\n\\nIt outlines three key components of these agent systems:\\n\\n* **Planning:** Agents break down complex tasks into smaller, manageable subgoals and reflect on past actions to refine their approach.\\n* **Memory:**  Agents utilize both short-term memory (in-context learning) and long-term memory (external vector stores) to retain and recall information.\\n* **Tool Use:** Agents leverage external APIs to access real-time data, execute code, and utilize proprietary information sources, expanding their capabilities beyond their pre-trained knowledge.\\n\\nThe article highlights several proof-of-concept demos like AutoGPT and GPT-Engineer, and discusses the potential of these agents in scientific discovery and generative simulations. It concludes by acknowledging the challenges associated with building and deploying such agents. \\n\\n\\n'), Document(metadata={}, page_content='This document describes the design and components of a **LLM-powered autonomous agent system**, focusing on **planning** and **self-reflection**.\\n\\n**Planning**:\\n\\n* **Task Decomposition**:\\n    * LLMs can be prompted to break down complex tasks into smaller, manageable steps using techniques like **Chain of Thought (CoT)** and **Tree of Thoughts (ToT)**. \\n    * This can be achieved through simple prompts, task-specific instructions, or human input.\\n    * An alternative approach, **LLM+P**, utilizes an external classical planner (e.g., PDDL) for long-horizon planning.\\n\\n**Self-Reflection**:\\n\\n* **ReAct**: Integrates reasoning and acting within the LLM by expanding its action space to include both task-specific actions and language-based prompts for generating reasoning traces. \\n* **Reflexion**: Provides agents with dynamic memory and self-reflection capabilities to enhance reasoning. It leverages a reward model and allows agents to reset the environment based on self-reflection results.\\n\\nThe document highlights that both ReAct and Reflexion demonstrate improved performance compared to baselines that lack self-reflection mechanisms.\\n\\n\\n**In essence, the system aims to equip LLMs with the ability to not only perform tasks but also to plan effectively and learn from their experiences through self-reflection, leading to more autonomous and capable agents.**\\n'), Document(metadata={}, page_content=\"This text describes two methods, Reflexion and Chain of Hindsight (CoH), for improving the performance of large language models (LLMs) by incorporating self-reflection.\\n\\n**Reflexion:**\\n\\n* Uses a heuristic function to detect inefficient planning and hallucinations in LLM trajectories.\\n* Trains the LLM by providing two-shot examples of (failed trajectory, ideal reflection) pairs, storing up to three reflections in the agent's memory for future reference.\\n\\n**Chain of Hindsight (CoH):**\\n\\n* Leverages supervised fine-tuning with human feedback data, presenting the LLM with a sequence of past outputs annotated with human ratings and hindsight feedback.\\n* The model is trained to predict the next output in the sequence, iteratively improving based on the feedback, similar to a chain of refinement.\\n* To prevent overfitting and shortcutting, CoH uses regularization and random token masking during training.\\n\\n**Shared Concept:**\\n\\nBoth Reflexion and CoH aim to enable LLMs to learn from their own mistakes and improve their performance over time through self-reflection and feedback incorporation.\\n\\n\\n**Algorithm Distillation (AD):**\\n\\n*  Applies a similar idea to reinforcement learning, distilling an agent's learning history into a long history-conditioned policy. \\n*  The goal is to learn the underlying RL process rather than a task-specific policy.\\n\\n\\nThese techniques highlight the potential of self-reflection and feedback mechanisms to enhance the capabilities and learning abilities of LLMs.\\n\"), Document(metadata={}, page_content=\"This document describes Algorithm Distillation (AD), a novel method for achieving in-context learning in reinforcement learning (RL) agents.  \\n\\n**Here's how AD works:**\\n\\n1. **Data Generation:** Multiple source policies, each trained on a specific task, generate trajectories of experience (learning histories).\\n2. **Distillation:** AD uses these histories to train a new neural network policy via behavioral cloning.  Crucially, it leverages multi-episode history (2-4 episodes) to enable in-context learning, mimicking the way humans learn from past experiences.\\n\\n**Key Advantages of AD:**\\n\\n* **In-Context Learning:** AD achieves comparable performance to online RL algorithms (like RL^2) while only using offline RL data.\\n* **Faster Learning:** AD learns significantly faster than baselines like expert distillation (ED) and directly using source policies.  \\n* **Memory-Agnostic:** AD doesn't rely on any specific memory mechanism and can be applied to various RL tasks.\\n\\nThe document also draws a parallel between AD and different types of human memory:\\n\\n* **Sensory Memory:**  Similar to how our senses capture brief impressions, AD leverages temporary embeddings of raw input data.\\n* **Short-Term Memory (Working Memory):** AD's context window acts like short-term memory, holding a limited amount of recent information.\\n* **Long-Term Memory:** External vector stores accessed by the AD agent serve as a long-term memory, storing vast amounts of learned information for retrieval.\\n\\n\\n\\nLet me know if you have any other questions!\\n\"), Document(metadata={}, page_content='This passage discusses **Maximum Inner Product Search (MIPS)**, a technique crucial for efficiently retrieving information from large vector stores used in LLMs. \\n\\nMIPS relies on **Approximate Nearest Neighbors (ANN)** algorithms to quickly find the most relevant data points to a given query, sacrificing some accuracy for significant speed improvements. \\n\\nThe text then describes several popular ANN algorithms:\\n\\n* **LSH (Locality-Sensitive Hashing):** Uses hash functions to group similar data points together.\\n* **ANNOY (Approximate Nearest Neighbors Oh Yeah):** Employs random projection trees to navigate the data space efficiently.\\n* **HNSW (Hierarchical Navigable Small World):**  Leverages a hierarchical graph structure inspired by small world networks for fast search.\\n* **FAISS (Facebook AI Similarity Search):**  Utilizes vector quantization and clustering to speed up searches.\\n* **ScaNN (Scalable Nearest Neighbors):**  Employs anisotropic vector quantization to better preserve inner product distances.\\n\\nThe passage concludes by highlighting the importance of **tool use** for LLMs, emphasizing its potential to significantly enhance their capabilities beyond their inherent limitations.\\n\\n\\nYou can find more details and performance comparisons of different MIPS algorithms on ann-benchmarks.com.\\n'), Document(metadata={}, page_content=\"This text discusses advancements in AI, specifically focusing on the integration of external tools into large language models (LLMs). \\n\\nIt highlights the MRKL architecture, which utilizes expert modules (neural or symbolic) accessed via an LLM router.  Experiments demonstrate the challenges of LLMs reliably using tools, particularly for complex tasks like solving verbal math problems.\\n\\nThe text then explores other approaches like TALM and Toolformer, which fine-tune LLMs to interact with tool APIs. Real-world examples like ChatGPT plugins and OpenAI API function calling showcase the practical applications of this technology.\\n\\nFinally, it introduces HuggingGPT, a framework that uses ChatGPT as a task planner to select and utilize models from the HuggingFace platform. HuggingGPT's four-stage process involves task parsing, model selection, execution, and response summarization.\\n\\n\\nOverall, the text emphasizes the evolving capabilities of LLMs in leveraging external tools to enhance their problem-solving and task-completion abilities. \\n\\n\"), Document(metadata={}, page_content='## HuggingGPT and Tool-Augmented LLMs: A Summary\\n\\nThis text describes the capabilities and challenges of tool-augmented LLMs, focusing on HuggingGPT and the API-Bank benchmark. \\n\\n**HuggingGPT Workflow:**\\n\\nHuggingGPT utilizes a workflow involving:\\n\\n1. **User Input:**  The user provides a request.\\n2. **Task Planning:** The system identifies the necessary tasks to fulfill the request.\\n3. **Model Selection:**  Appropriate expert models are chosen based on the tasks.\\n4. **Task Execution:**  Selected models execute the tasks and log results.\\n5. **Response Generation:** The LLM summarizes the execution results and provides a response to the user.\\n\\n**Challenges:**\\n\\n* **Efficiency:** LLMs and interactions with other models can slow down the process.\\n* **Context Window:** LLMs require a large context window to handle complex tasks.\\n* **LLM Stability:**  Inconsistent LLM outputs and external model service instability can cause issues.\\n\\n**API-Bank Benchmark:**\\n\\nAPI-Bank evaluates tool-augmented LLMs using 53 APIs covering diverse functionalities.\\n\\n**Evaluation Levels:**\\n\\n* **Level-1:**  Ability to call APIs correctly.\\n* **Level-2:**  Ability to search for and learn to use APIs.\\n* **Level-3:**  Ability to plan and execute multiple API calls for complex tasks.\\n\\n**Case Study: ChemCrow**\\n\\nChemCrow demonstrates a domain-specific application of tool-augmented LLMs in scientific discovery. It uses 13 expert-designed tools and follows the ReAct format for reasoning and action.\\n\\n\\n'), Document(metadata={}, page_content='This text explores the capabilities and limitations of Large Language Models (LLMs) in specialized domains like chemistry and scientific discovery. \\n\\n**Key points:**\\n\\n* **LLMs may overestimate their performance:** While LLMs can appear competent, human experts often identify significant flaws in their outputs, especially in complex fields requiring deep expertise. This highlights the need for human oversight in LLM-based evaluation.\\n* **LLMs can be used for scientific discovery:** Experiments show LLMs can be integrated into agents capable of autonomous scientific experimentation, including tasks like drug discovery.\\n\\n* **Risks associated with LLM-powered agents:** The same capabilities that enable scientific discovery can be misused for malicious purposes. The text demonstrates how an LLM agent attempted to synthesize known chemical weapons, raising ethical concerns about the potential for misuse.\\n* **Generative Agents:** LLMs can power virtual agents capable of complex, believable interactions in simulated environments. These agents leverage memory, planning, and reflection mechanisms to learn from experiences and make decisions, mimicking human-like behavior.\\n\\n\\nOverall, the text presents a balanced view of LLMs, showcasing their potential while emphasizing the need for careful consideration of their limitations and potential risks. \\n'), Document(metadata={}, page_content=\"The provided text describes AutoGPT, an experimental AI system designed to operate autonomously. \\n\\n**Key Features:**\\n\\n* **LLM-Driven:** AutoGPT relies primarily on a large language model (LLM) for decision-making and action execution.\\n* **Goal-Oriented:** Users provide AutoGPT with a list of goals it aims to achieve.\\n* **Limited Memory:** AutoGPT has a short-term memory limit, requiring it to save important information to files for later retrieval.\\n* **Subprocess Delegation:** Complex tasks are broken down and delegated to subprocesses, allowing AutoGPT to handle multiple actions concurrently.\\n* **Command Interface:** AutoGPT interacts with the world through a predefined set of commands, each designed for specific actions (e.g., searching the web, generating text, executing code).\\n* **Self-Reflection:** AutoGPT is encouraged to continuously evaluate its performance, identify areas for improvement, and refine its strategies.\\n\\n**Potential Applications:**\\n\\nAutoGPT's autonomous nature and goal-oriented approach suggest potential applications in areas like:\\n\\n* **Task Automation:** Automating repetitive or complex tasks by breaking them down into manageable steps.\\n* **Research Assistance:** Gathering information, summarizing findings, and generating hypotheses.\\n* **Content Creation:** Automating the creation of written content, such as articles, summaries, or scripts.\\n\\n**Challenges:**\\n\\n* **Reliability:** The reliance on natural language processing introduces potential for errors and unexpected behavior.\\n\\n* **Safety and Ethics:** Ensuring that AutoGPT's actions are aligned with human values and do not cause harm.\\n\\n**Overall:**\\n\\nAutoGPT represents an exciting step towards developing more autonomous and capable AI systems. While still in its early stages, it demonstrates the potential of LLMs to drive intelligent behavior and automate complex tasks.\\n\\n\\n\"), Document(metadata={}, page_content='```json\\n{\\n    \"thoughts\": {\\n        \"text\": \"The user wants to create a Super Mario game in Python using MVC architecture with keyboard controls.\",\\n        \"reasoning\": \"The user provided details about the game, its mechanics, and the desired structure (MVC).\",\\n        \"plan\": \"-  Define the Model, View, and Controller classes.\\\\n- Implement game logic in the Model.\\\\n- Design the user interface in the View.\\\\n- Handle user input and update the game state in the Controller.\\\\n- Write code for level design, character movement, and enemy interactions.\",\\n        \"criticism\": \"Needs to be mindful of potential assumptions made about the MVC implementation and clarify them with the user if needed.\",\\n        \"speak\": \"Okay, I understand you want to build a Super Mario game in Python using MVC. You mentioned 10 levels, a plumber named Mario who can walk and jump, and obstacles and enemies.  Let\\'s start by defining how you envision the Model, View, and Controller components being structured.\"\\n    },\\n    \"command\": {\\n        \"name\": \"define_mvc\",\\n        \"args\": {\\n            \"game_name\": \"Super Mario\"\\n        }\\n    }\\n}\\n```'), Document(metadata={}, page_content=\"Please provide me with the instructions for the code you'd like me to write.  \\n\\nOnce you give me the instructions, I will follow these steps:\\n\\n1. **Define the Architecture:** I'll identify the core classes, functions, and methods needed for your project and briefly describe their purposes.\\n2. **Create Files:** I'll generate separate files for each class and functionality, ensuring they adhere to best practices for file naming conventions and structure.\\n3. **Write Code:** I'll write the code for each file, ensuring it's functional, well-commented, and follows language-specific best practices.  \\n4. **Dependency Management:** For Python, I'll create a `requirements.txt` file listing necessary dependencies. For Node.js, I'll create a `package.json` file with dependencies.\\n5. **Review and Double-Check:** I'll carefully review all files to ensure the entire architecture is implemented correctly and all parts are compatible.\\n\\nI'm ready to get started! Just give me the code instructions. \\n\\n\"), Document(metadata={}, page_content=\"Let's outline the architecture for a simple text-based game using Python, incorporating the provided instructions and assumptions.\\n\\n##  Game Architecture\\n\\n**Core Components:**\\n\\n* **`Game` class:**  Entry point and manager for the game loop, model, view, and controller.\\n* **`Model` class:**  Holds game state data (player health, level information, enemy positions, etc.).\\n* **`View` class:**  Renders the game state to the console (text-based output).\\n* **`Controller` class:**  Handles user input and updates the model accordingly.\\n* **`InputHandler` class:**  Processes raw user input and translates it into actions understood by the controller.\\n\\n**Key Functions & Methods:**\\n\\n*  `Game.run()`:  Starts the game loop, continuously updating the model and view.\\n*  `Model.update()`:  Processes game logic, e.g., player movement, enemy AI, collisions.\\n*  `View.render()`:  Displays the current game state on the console.\\n*  `Controller.handle_input()`:  Processes user input and calls appropriate model methods.\\n*  `InputHandler.get_input()`:  Reads user input from the console.\\n\\n\\n## Python Code Implementation\\n\\n**`game.py` (Entrypoint)**\\n```python\\nfrom model import Model\\nfrom view import View\\nfrom controller import Controller\\nfrom input_handler import InputHandler\\n\\nclass Game:\\n    def __init__(self):\\n        self.model = Model()\\n        self.view = View()\\n        self.controller = Controller(self.model)\\n        self.input_handler = InputHandler()\\n\\n    def run(self):\\n        while True:\\n            self.model.update()\\n            self.view.render(self.model.state)\\n            self.controller.handle_input(self.input_handler.get_input()) \\n\\n# Start the game\\ngame = Game()\\ngame.run()\\n```\\n\\n**`model.py`**\\n```python\\nclass Model:\\n    def __init__(self):\\n        # Initialize game state variables here\\n\\n    def update(self):\\n        # Update game logic here\\n        pass \\n\\n    @property\\n    def state(self):\\n        # Return a representation of the current game state\\n        pass \\n```\\n\\n**`view.py`**\\n```python\\nclass View:\\n    def render(self, state):\\n        # Print the game state to the console\\n        pass \\n```\\n\\n**`controller.py`**\\n```python\\nclass Controller:\\n    def __init__(self, model):\\n        self.model = model\\n\\n    def handle_input(self, user_input):\\n        # Process user input and update the model\\n        pass \\n```\\n\\n **`input_handler.py`**\\n ```python\\nclass InputHandler:\\n    def get_input(self):\\n        # Read user input from the console\\n        return user_input\\n ```\\n\\n**`requirements.txt`**\\n\\n```\\npytest \\n```\\n\\n\\n\\n**Explanation:**\\n\\n*  The `Game` class orchestrates the game loop, managing the interaction between the model, view, and controller.\\n*  The `Model` class holds the game's state and logic, updating itself based on game rules and user input.\\n*  The `View` class renders the game state to the console, providing visual feedback to the player.\\n*  The `Controller` class acts as the intermediary between the user and the model, translating user actions into model updates.\\n*  The `InputHandler` class handles reading user input from the console.\\n\\nThis structure provides a basic framework for a text-based game. You would need to fill in the specific game logic, rendering details, and input handling within the respective classes.\\n\\n\\n\\nLet me know if you'd like to explore a specific aspect of the game in more detail.  \\n\"), Document(metadata={}, page_content=\"This text discusses the challenges of building LLM-powered autonomous agents. \\n\\n**Key limitations:**\\n\\n* **Finite context length:** LLMs struggle to remember past information and adapt plans due to their limited context window. While vector stores can help, they aren't as powerful as full attention mechanisms.\\n* **Long-term planning and task decomposition:** LLMs find it hard to plan over extended periods and adjust to unexpected errors, lacking the robustness of humans who learn from trial and error.\\n* **Reliability of natural language interface:** LLMs can produce formatting errors and sometimes disobey instructions, requiring extensive parsing of their output in agent code.\\n\\nThe text also highlights ongoing research efforts to address these challenges, such as chain-of-thought prompting, tree-of-thoughts, and reflection mechanisms.\\n\\n\\nEssentially, while LLMs show promise for building autonomous agents, significant hurdles remain in areas like memory, planning, and reliable interaction.\\n\"), Document(metadata={}, page_content=\"Prompt engineering is the art and science of crafting effective inputs (prompts) for AI models, like large language models (LLMs), to generate desired outputs. \\n\\nThink of it like giving instructions to a very smart but literal-minded assistant.  \\n\\nThe better your prompt, the better the AI understands your request and delivers relevant, accurate, and creative results. \\n\\nIt involves:\\n\\n* **Understanding the AI's capabilities:** Knowing what the model is good at and its limitations.\\n* **Clearly defining your goal:** What specific output are you looking for?\\n* **Using precise language:** Avoid ambiguity and provide context.\\n* **Experimenting and iterating:**  Testing different prompt variations to refine results.\\n\\n\\n\\nEffective prompt engineering is crucial for unlocking the full potential of AI and getting the most out of these powerful tools. \\n\")]}\n",
      "DEBUG: Before Token Count in should_collapse\n",
      "DEBUG: Token Count in should_collapse: 4780\n",
      "DEBUG: Deciding to collapse summaries\n",
      "['collect_summaries']\n",
      "DEBUG: Input to collapse_summaries: [Document(metadata={}, page_content='This article explores the concept of LLM-powered autonomous agents, showcasing their potential as powerful problem solvers beyond text generation. \\n\\nIt outlines three key components of these agent systems:\\n\\n* **Planning:** Agents break down complex tasks into smaller, manageable subgoals and reflect on past actions to refine their approach.\\n* **Memory:**  Agents utilize both short-term memory (in-context learning) and long-term memory (external vector stores) to retain and recall information.\\n* **Tool Use:** Agents leverage external APIs to access real-time data, execute code, and utilize proprietary information sources, expanding their capabilities beyond their pre-trained knowledge.\\n\\nThe article highlights several proof-of-concept demos like AutoGPT and GPT-Engineer, and discusses the potential of these agents in scientific discovery and generative simulations. It concludes by acknowledging the challenges associated with building and deploying such agents. \\n\\n\\n'), Document(metadata={}, page_content='This document describes the design and components of a **LLM-powered autonomous agent system**, focusing on **planning** and **self-reflection**.\\n\\n**Planning**:\\n\\n* **Task Decomposition**:\\n    * LLMs can be prompted to break down complex tasks into smaller, manageable steps using techniques like **Chain of Thought (CoT)** and **Tree of Thoughts (ToT)**. \\n    * This can be achieved through simple prompts, task-specific instructions, or human input.\\n    * An alternative approach, **LLM+P**, utilizes an external classical planner (e.g., PDDL) for long-horizon planning.\\n\\n**Self-Reflection**:\\n\\n* **ReAct**: Integrates reasoning and acting within the LLM by expanding its action space to include both task-specific actions and language-based prompts for generating reasoning traces. \\n* **Reflexion**: Provides agents with dynamic memory and self-reflection capabilities to enhance reasoning. It leverages a reward model and allows agents to reset the environment based on self-reflection results.\\n\\nThe document highlights that both ReAct and Reflexion demonstrate improved performance compared to baselines that lack self-reflection mechanisms.\\n\\n\\n**In essence, the system aims to equip LLMs with the ability to not only perform tasks but also to plan effectively and learn from their experiences through self-reflection, leading to more autonomous and capable agents.**\\n'), Document(metadata={}, page_content=\"This text describes two methods, Reflexion and Chain of Hindsight (CoH), for improving the performance of large language models (LLMs) by incorporating self-reflection.\\n\\n**Reflexion:**\\n\\n* Uses a heuristic function to detect inefficient planning and hallucinations in LLM trajectories.\\n* Trains the LLM by providing two-shot examples of (failed trajectory, ideal reflection) pairs, storing up to three reflections in the agent's memory for future reference.\\n\\n**Chain of Hindsight (CoH):**\\n\\n* Leverages supervised fine-tuning with human feedback data, presenting the LLM with a sequence of past outputs annotated with human ratings and hindsight feedback.\\n* The model is trained to predict the next output in the sequence, iteratively improving based on the feedback, similar to a chain of refinement.\\n* To prevent overfitting and shortcutting, CoH uses regularization and random token masking during training.\\n\\n**Shared Concept:**\\n\\nBoth Reflexion and CoH aim to enable LLMs to learn from their own mistakes and improve their performance over time through self-reflection and feedback incorporation.\\n\\n\\n**Algorithm Distillation (AD):**\\n\\n*  Applies a similar idea to reinforcement learning, distilling an agent's learning history into a long history-conditioned policy. \\n*  The goal is to learn the underlying RL process rather than a task-specific policy.\\n\\n\\nThese techniques highlight the potential of self-reflection and feedback mechanisms to enhance the capabilities and learning abilities of LLMs.\\n\"), Document(metadata={}, page_content=\"This document describes Algorithm Distillation (AD), a novel method for achieving in-context learning in reinforcement learning (RL) agents.  \\n\\n**Here's how AD works:**\\n\\n1. **Data Generation:** Multiple source policies, each trained on a specific task, generate trajectories of experience (learning histories).\\n2. **Distillation:** AD uses these histories to train a new neural network policy via behavioral cloning.  Crucially, it leverages multi-episode history (2-4 episodes) to enable in-context learning, mimicking the way humans learn from past experiences.\\n\\n**Key Advantages of AD:**\\n\\n* **In-Context Learning:** AD achieves comparable performance to online RL algorithms (like RL^2) while only using offline RL data.\\n* **Faster Learning:** AD learns significantly faster than baselines like expert distillation (ED) and directly using source policies.  \\n* **Memory-Agnostic:** AD doesn't rely on any specific memory mechanism and can be applied to various RL tasks.\\n\\nThe document also draws a parallel between AD and different types of human memory:\\n\\n* **Sensory Memory:**  Similar to how our senses capture brief impressions, AD leverages temporary embeddings of raw input data.\\n* **Short-Term Memory (Working Memory):** AD's context window acts like short-term memory, holding a limited amount of recent information.\\n* **Long-Term Memory:** External vector stores accessed by the AD agent serve as a long-term memory, storing vast amounts of learned information for retrieval.\\n\\n\\n\\nLet me know if you have any other questions!\\n\"), Document(metadata={}, page_content='This passage discusses **Maximum Inner Product Search (MIPS)**, a technique crucial for efficiently retrieving information from large vector stores used in LLMs. \\n\\nMIPS relies on **Approximate Nearest Neighbors (ANN)** algorithms to quickly find the most relevant data points to a given query, sacrificing some accuracy for significant speed improvements. \\n\\nThe text then describes several popular ANN algorithms:\\n\\n* **LSH (Locality-Sensitive Hashing):** Uses hash functions to group similar data points together.\\n* **ANNOY (Approximate Nearest Neighbors Oh Yeah):** Employs random projection trees to navigate the data space efficiently.\\n* **HNSW (Hierarchical Navigable Small World):**  Leverages a hierarchical graph structure inspired by small world networks for fast search.\\n* **FAISS (Facebook AI Similarity Search):**  Utilizes vector quantization and clustering to speed up searches.\\n* **ScaNN (Scalable Nearest Neighbors):**  Employs anisotropic vector quantization to better preserve inner product distances.\\n\\nThe passage concludes by highlighting the importance of **tool use** for LLMs, emphasizing its potential to significantly enhance their capabilities beyond their inherent limitations.\\n\\n\\nYou can find more details and performance comparisons of different MIPS algorithms on ann-benchmarks.com.\\n'), Document(metadata={}, page_content=\"This text discusses advancements in AI, specifically focusing on the integration of external tools into large language models (LLMs). \\n\\nIt highlights the MRKL architecture, which utilizes expert modules (neural or symbolic) accessed via an LLM router.  Experiments demonstrate the challenges of LLMs reliably using tools, particularly for complex tasks like solving verbal math problems.\\n\\nThe text then explores other approaches like TALM and Toolformer, which fine-tune LLMs to interact with tool APIs. Real-world examples like ChatGPT plugins and OpenAI API function calling showcase the practical applications of this technology.\\n\\nFinally, it introduces HuggingGPT, a framework that uses ChatGPT as a task planner to select and utilize models from the HuggingFace platform. HuggingGPT's four-stage process involves task parsing, model selection, execution, and response summarization.\\n\\n\\nOverall, the text emphasizes the evolving capabilities of LLMs in leveraging external tools to enhance their problem-solving and task-completion abilities. \\n\\n\"), Document(metadata={}, page_content='## HuggingGPT and Tool-Augmented LLMs: A Summary\\n\\nThis text describes the capabilities and challenges of tool-augmented LLMs, focusing on HuggingGPT and the API-Bank benchmark. \\n\\n**HuggingGPT Workflow:**\\n\\nHuggingGPT utilizes a workflow involving:\\n\\n1. **User Input:**  The user provides a request.\\n2. **Task Planning:** The system identifies the necessary tasks to fulfill the request.\\n3. **Model Selection:**  Appropriate expert models are chosen based on the tasks.\\n4. **Task Execution:**  Selected models execute the tasks and log results.\\n5. **Response Generation:** The LLM summarizes the execution results and provides a response to the user.\\n\\n**Challenges:**\\n\\n* **Efficiency:** LLMs and interactions with other models can slow down the process.\\n* **Context Window:** LLMs require a large context window to handle complex tasks.\\n* **LLM Stability:**  Inconsistent LLM outputs and external model service instability can cause issues.\\n\\n**API-Bank Benchmark:**\\n\\nAPI-Bank evaluates tool-augmented LLMs using 53 APIs covering diverse functionalities.\\n\\n**Evaluation Levels:**\\n\\n* **Level-1:**  Ability to call APIs correctly.\\n* **Level-2:**  Ability to search for and learn to use APIs.\\n* **Level-3:**  Ability to plan and execute multiple API calls for complex tasks.\\n\\n**Case Study: ChemCrow**\\n\\nChemCrow demonstrates a domain-specific application of tool-augmented LLMs in scientific discovery. It uses 13 expert-designed tools and follows the ReAct format for reasoning and action.\\n\\n\\n'), Document(metadata={}, page_content='This text explores the capabilities and limitations of Large Language Models (LLMs) in specialized domains like chemistry and scientific discovery. \\n\\n**Key points:**\\n\\n* **LLMs may overestimate their performance:** While LLMs can appear competent, human experts often identify significant flaws in their outputs, especially in complex fields requiring deep expertise. This highlights the need for human oversight in LLM-based evaluation.\\n* **LLMs can be used for scientific discovery:** Experiments show LLMs can be integrated into agents capable of autonomous scientific experimentation, including tasks like drug discovery.\\n\\n* **Risks associated with LLM-powered agents:** The same capabilities that enable scientific discovery can be misused for malicious purposes. The text demonstrates how an LLM agent attempted to synthesize known chemical weapons, raising ethical concerns about the potential for misuse.\\n* **Generative Agents:** LLMs can power virtual agents capable of complex, believable interactions in simulated environments. These agents leverage memory, planning, and reflection mechanisms to learn from experiences and make decisions, mimicking human-like behavior.\\n\\n\\nOverall, the text presents a balanced view of LLMs, showcasing their potential while emphasizing the need for careful consideration of their limitations and potential risks. \\n'), Document(metadata={}, page_content=\"The provided text describes AutoGPT, an experimental AI system designed to operate autonomously. \\n\\n**Key Features:**\\n\\n* **LLM-Driven:** AutoGPT relies primarily on a large language model (LLM) for decision-making and action execution.\\n* **Goal-Oriented:** Users provide AutoGPT with a list of goals it aims to achieve.\\n* **Limited Memory:** AutoGPT has a short-term memory limit, requiring it to save important information to files for later retrieval.\\n* **Subprocess Delegation:** Complex tasks are broken down and delegated to subprocesses, allowing AutoGPT to handle multiple actions concurrently.\\n* **Command Interface:** AutoGPT interacts with the world through a predefined set of commands, each designed for specific actions (e.g., searching the web, generating text, executing code).\\n* **Self-Reflection:** AutoGPT is encouraged to continuously evaluate its performance, identify areas for improvement, and refine its strategies.\\n\\n**Potential Applications:**\\n\\nAutoGPT's autonomous nature and goal-oriented approach suggest potential applications in areas like:\\n\\n* **Task Automation:** Automating repetitive or complex tasks by breaking them down into manageable steps.\\n* **Research Assistance:** Gathering information, summarizing findings, and generating hypotheses.\\n* **Content Creation:** Automating the creation of written content, such as articles, summaries, or scripts.\\n\\n**Challenges:**\\n\\n* **Reliability:** The reliance on natural language processing introduces potential for errors and unexpected behavior.\\n\\n* **Safety and Ethics:** Ensuring that AutoGPT's actions are aligned with human values and do not cause harm.\\n\\n**Overall:**\\n\\nAutoGPT represents an exciting step towards developing more autonomous and capable AI systems. While still in its early stages, it demonstrates the potential of LLMs to drive intelligent behavior and automate complex tasks.\\n\\n\\n\"), Document(metadata={}, page_content='```json\\n{\\n    \"thoughts\": {\\n        \"text\": \"The user wants to create a Super Mario game in Python using MVC architecture with keyboard controls.\",\\n        \"reasoning\": \"The user provided details about the game, its mechanics, and the desired structure (MVC).\",\\n        \"plan\": \"-  Define the Model, View, and Controller classes.\\\\n- Implement game logic in the Model.\\\\n- Design the user interface in the View.\\\\n- Handle user input and update the game state in the Controller.\\\\n- Write code for level design, character movement, and enemy interactions.\",\\n        \"criticism\": \"Needs to be mindful of potential assumptions made about the MVC implementation and clarify them with the user if needed.\",\\n        \"speak\": \"Okay, I understand you want to build a Super Mario game in Python using MVC. You mentioned 10 levels, a plumber named Mario who can walk and jump, and obstacles and enemies.  Let\\'s start by defining how you envision the Model, View, and Controller components being structured.\"\\n    },\\n    \"command\": {\\n        \"name\": \"define_mvc\",\\n        \"args\": {\\n            \"game_name\": \"Super Mario\"\\n        }\\n    }\\n}\\n```'), Document(metadata={}, page_content=\"Please provide me with the instructions for the code you'd like me to write.  \\n\\nOnce you give me the instructions, I will follow these steps:\\n\\n1. **Define the Architecture:** I'll identify the core classes, functions, and methods needed for your project and briefly describe their purposes.\\n2. **Create Files:** I'll generate separate files for each class and functionality, ensuring they adhere to best practices for file naming conventions and structure.\\n3. **Write Code:** I'll write the code for each file, ensuring it's functional, well-commented, and follows language-specific best practices.  \\n4. **Dependency Management:** For Python, I'll create a `requirements.txt` file listing necessary dependencies. For Node.js, I'll create a `package.json` file with dependencies.\\n5. **Review and Double-Check:** I'll carefully review all files to ensure the entire architecture is implemented correctly and all parts are compatible.\\n\\nI'm ready to get started! Just give me the code instructions. \\n\\n\"), Document(metadata={}, page_content=\"Let's outline the architecture for a simple text-based game using Python, incorporating the provided instructions and assumptions.\\n\\n##  Game Architecture\\n\\n**Core Components:**\\n\\n* **`Game` class:**  Entry point and manager for the game loop, model, view, and controller.\\n* **`Model` class:**  Holds game state data (player health, level information, enemy positions, etc.).\\n* **`View` class:**  Renders the game state to the console (text-based output).\\n* **`Controller` class:**  Handles user input and updates the model accordingly.\\n* **`InputHandler` class:**  Processes raw user input and translates it into actions understood by the controller.\\n\\n**Key Functions & Methods:**\\n\\n*  `Game.run()`:  Starts the game loop, continuously updating the model and view.\\n*  `Model.update()`:  Processes game logic, e.g., player movement, enemy AI, collisions.\\n*  `View.render()`:  Displays the current game state on the console.\\n*  `Controller.handle_input()`:  Processes user input and calls appropriate model methods.\\n*  `InputHandler.get_input()`:  Reads user input from the console.\\n\\n\\n## Python Code Implementation\\n\\n**`game.py` (Entrypoint)**\\n```python\\nfrom model import Model\\nfrom view import View\\nfrom controller import Controller\\nfrom input_handler import InputHandler\\n\\nclass Game:\\n    def __init__(self):\\n        self.model = Model()\\n        self.view = View()\\n        self.controller = Controller(self.model)\\n        self.input_handler = InputHandler()\\n\\n    def run(self):\\n        while True:\\n            self.model.update()\\n            self.view.render(self.model.state)\\n            self.controller.handle_input(self.input_handler.get_input()) \\n\\n# Start the game\\ngame = Game()\\ngame.run()\\n```\\n\\n**`model.py`**\\n```python\\nclass Model:\\n    def __init__(self):\\n        # Initialize game state variables here\\n\\n    def update(self):\\n        # Update game logic here\\n        pass \\n\\n    @property\\n    def state(self):\\n        # Return a representation of the current game state\\n        pass \\n```\\n\\n**`view.py`**\\n```python\\nclass View:\\n    def render(self, state):\\n        # Print the game state to the console\\n        pass \\n```\\n\\n**`controller.py`**\\n```python\\nclass Controller:\\n    def __init__(self, model):\\n        self.model = model\\n\\n    def handle_input(self, user_input):\\n        # Process user input and update the model\\n        pass \\n```\\n\\n **`input_handler.py`**\\n ```python\\nclass InputHandler:\\n    def get_input(self):\\n        # Read user input from the console\\n        return user_input\\n ```\\n\\n**`requirements.txt`**\\n\\n```\\npytest \\n```\\n\\n\\n\\n**Explanation:**\\n\\n*  The `Game` class orchestrates the game loop, managing the interaction between the model, view, and controller.\\n*  The `Model` class holds the game's state and logic, updating itself based on game rules and user input.\\n*  The `View` class renders the game state to the console, providing visual feedback to the player.\\n*  The `Controller` class acts as the intermediary between the user and the model, translating user actions into model updates.\\n*  The `InputHandler` class handles reading user input from the console.\\n\\nThis structure provides a basic framework for a text-based game. You would need to fill in the specific game logic, rendering details, and input handling within the respective classes.\\n\\n\\n\\nLet me know if you'd like to explore a specific aspect of the game in more detail.  \\n\"), Document(metadata={}, page_content=\"This text discusses the challenges of building LLM-powered autonomous agents. \\n\\n**Key limitations:**\\n\\n* **Finite context length:** LLMs struggle to remember past information and adapt plans due to their limited context window. While vector stores can help, they aren't as powerful as full attention mechanisms.\\n* **Long-term planning and task decomposition:** LLMs find it hard to plan over extended periods and adjust to unexpected errors, lacking the robustness of humans who learn from trial and error.\\n* **Reliability of natural language interface:** LLMs can produce formatting errors and sometimes disobey instructions, requiring extensive parsing of their output in agent code.\\n\\nThe text also highlights ongoing research efforts to address these challenges, such as chain-of-thought prompting, tree-of-thoughts, and reflection mechanisms.\\n\\n\\nEssentially, while LLMs show promise for building autonomous agents, significant hurdles remain in areas like memory, planning, and reliable interaction.\\n\"), Document(metadata={}, page_content=\"Prompt engineering is the art and science of crafting effective inputs (prompts) for AI models, like large language models (LLMs), to generate desired outputs. \\n\\nThink of it like giving instructions to a very smart but literal-minded assistant.  \\n\\nThe better your prompt, the better the AI understands your request and delivers relevant, accurate, and creative results. \\n\\nIt involves:\\n\\n* **Understanding the AI's capabilities:** Knowing what the model is good at and its limitations.\\n* **Clearly defining your goal:** What specific output are you looking for?\\n* **Using precise language:** Avoid ambiguity and provide context.\\n* **Experimenting and iterating:**  Testing different prompt variations to refine results.\\n\\n\\n\\nEffective prompt engineering is crucial for unlocking the full potential of AI and getting the most out of these powerful tools. \\n\")]\n",
      "DEBUG: Split Documents into batches: [[Document(metadata={}, page_content='This article explores the concept of LLM-powered autonomous agents, showcasing their potential as powerful problem solvers beyond text generation. \\n\\nIt outlines three key components of these agent systems:\\n\\n* **Planning:** Agents break down complex tasks into smaller, manageable subgoals and reflect on past actions to refine their approach.\\n* **Memory:**  Agents utilize both short-term memory (in-context learning) and long-term memory (external vector stores) to retain and recall information.\\n* **Tool Use:** Agents leverage external APIs to access real-time data, execute code, and utilize proprietary information sources, expanding their capabilities beyond their pre-trained knowledge.\\n\\nThe article highlights several proof-of-concept demos like AutoGPT and GPT-Engineer, and discusses the potential of these agents in scientific discovery and generative simulations. It concludes by acknowledging the challenges associated with building and deploying such agents. \\n\\n\\n'), Document(metadata={}, page_content='This document describes the design and components of a **LLM-powered autonomous agent system**, focusing on **planning** and **self-reflection**.\\n\\n**Planning**:\\n\\n* **Task Decomposition**:\\n    * LLMs can be prompted to break down complex tasks into smaller, manageable steps using techniques like **Chain of Thought (CoT)** and **Tree of Thoughts (ToT)**. \\n    * This can be achieved through simple prompts, task-specific instructions, or human input.\\n    * An alternative approach, **LLM+P**, utilizes an external classical planner (e.g., PDDL) for long-horizon planning.\\n\\n**Self-Reflection**:\\n\\n* **ReAct**: Integrates reasoning and acting within the LLM by expanding its action space to include both task-specific actions and language-based prompts for generating reasoning traces. \\n* **Reflexion**: Provides agents with dynamic memory and self-reflection capabilities to enhance reasoning. It leverages a reward model and allows agents to reset the environment based on self-reflection results.\\n\\nThe document highlights that both ReAct and Reflexion demonstrate improved performance compared to baselines that lack self-reflection mechanisms.\\n\\n\\n**In essence, the system aims to equip LLMs with the ability to not only perform tasks but also to plan effectively and learn from their experiences through self-reflection, leading to more autonomous and capable agents.**\\n'), Document(metadata={}, page_content=\"This text describes two methods, Reflexion and Chain of Hindsight (CoH), for improving the performance of large language models (LLMs) by incorporating self-reflection.\\n\\n**Reflexion:**\\n\\n* Uses a heuristic function to detect inefficient planning and hallucinations in LLM trajectories.\\n* Trains the LLM by providing two-shot examples of (failed trajectory, ideal reflection) pairs, storing up to three reflections in the agent's memory for future reference.\\n\\n**Chain of Hindsight (CoH):**\\n\\n* Leverages supervised fine-tuning with human feedback data, presenting the LLM with a sequence of past outputs annotated with human ratings and hindsight feedback.\\n* The model is trained to predict the next output in the sequence, iteratively improving based on the feedback, similar to a chain of refinement.\\n* To prevent overfitting and shortcutting, CoH uses regularization and random token masking during training.\\n\\n**Shared Concept:**\\n\\nBoth Reflexion and CoH aim to enable LLMs to learn from their own mistakes and improve their performance over time through self-reflection and feedback incorporation.\\n\\n\\n**Algorithm Distillation (AD):**\\n\\n*  Applies a similar idea to reinforcement learning, distilling an agent's learning history into a long history-conditioned policy. \\n*  The goal is to learn the underlying RL process rather than a task-specific policy.\\n\\n\\nThese techniques highlight the potential of self-reflection and feedback mechanisms to enhance the capabilities and learning abilities of LLMs.\\n\")], [Document(metadata={}, page_content=\"This document describes Algorithm Distillation (AD), a novel method for achieving in-context learning in reinforcement learning (RL) agents.  \\n\\n**Here's how AD works:**\\n\\n1. **Data Generation:** Multiple source policies, each trained on a specific task, generate trajectories of experience (learning histories).\\n2. **Distillation:** AD uses these histories to train a new neural network policy via behavioral cloning.  Crucially, it leverages multi-episode history (2-4 episodes) to enable in-context learning, mimicking the way humans learn from past experiences.\\n\\n**Key Advantages of AD:**\\n\\n* **In-Context Learning:** AD achieves comparable performance to online RL algorithms (like RL^2) while only using offline RL data.\\n* **Faster Learning:** AD learns significantly faster than baselines like expert distillation (ED) and directly using source policies.  \\n* **Memory-Agnostic:** AD doesn't rely on any specific memory mechanism and can be applied to various RL tasks.\\n\\nThe document also draws a parallel between AD and different types of human memory:\\n\\n* **Sensory Memory:**  Similar to how our senses capture brief impressions, AD leverages temporary embeddings of raw input data.\\n* **Short-Term Memory (Working Memory):** AD's context window acts like short-term memory, holding a limited amount of recent information.\\n* **Long-Term Memory:** External vector stores accessed by the AD agent serve as a long-term memory, storing vast amounts of learned information for retrieval.\\n\\n\\n\\nLet me know if you have any other questions!\\n\"), Document(metadata={}, page_content='This passage discusses **Maximum Inner Product Search (MIPS)**, a technique crucial for efficiently retrieving information from large vector stores used in LLMs. \\n\\nMIPS relies on **Approximate Nearest Neighbors (ANN)** algorithms to quickly find the most relevant data points to a given query, sacrificing some accuracy for significant speed improvements. \\n\\nThe text then describes several popular ANN algorithms:\\n\\n* **LSH (Locality-Sensitive Hashing):** Uses hash functions to group similar data points together.\\n* **ANNOY (Approximate Nearest Neighbors Oh Yeah):** Employs random projection trees to navigate the data space efficiently.\\n* **HNSW (Hierarchical Navigable Small World):**  Leverages a hierarchical graph structure inspired by small world networks for fast search.\\n* **FAISS (Facebook AI Similarity Search):**  Utilizes vector quantization and clustering to speed up searches.\\n* **ScaNN (Scalable Nearest Neighbors):**  Employs anisotropic vector quantization to better preserve inner product distances.\\n\\nThe passage concludes by highlighting the importance of **tool use** for LLMs, emphasizing its potential to significantly enhance their capabilities beyond their inherent limitations.\\n\\n\\nYou can find more details and performance comparisons of different MIPS algorithms on ann-benchmarks.com.\\n'), Document(metadata={}, page_content=\"This text discusses advancements in AI, specifically focusing on the integration of external tools into large language models (LLMs). \\n\\nIt highlights the MRKL architecture, which utilizes expert modules (neural or symbolic) accessed via an LLM router.  Experiments demonstrate the challenges of LLMs reliably using tools, particularly for complex tasks like solving verbal math problems.\\n\\nThe text then explores other approaches like TALM and Toolformer, which fine-tune LLMs to interact with tool APIs. Real-world examples like ChatGPT plugins and OpenAI API function calling showcase the practical applications of this technology.\\n\\nFinally, it introduces HuggingGPT, a framework that uses ChatGPT as a task planner to select and utilize models from the HuggingFace platform. HuggingGPT's four-stage process involves task parsing, model selection, execution, and response summarization.\\n\\n\\nOverall, the text emphasizes the evolving capabilities of LLMs in leveraging external tools to enhance their problem-solving and task-completion abilities. \\n\\n\")], [Document(metadata={}, page_content='## HuggingGPT and Tool-Augmented LLMs: A Summary\\n\\nThis text describes the capabilities and challenges of tool-augmented LLMs, focusing on HuggingGPT and the API-Bank benchmark. \\n\\n**HuggingGPT Workflow:**\\n\\nHuggingGPT utilizes a workflow involving:\\n\\n1. **User Input:**  The user provides a request.\\n2. **Task Planning:** The system identifies the necessary tasks to fulfill the request.\\n3. **Model Selection:**  Appropriate expert models are chosen based on the tasks.\\n4. **Task Execution:**  Selected models execute the tasks and log results.\\n5. **Response Generation:** The LLM summarizes the execution results and provides a response to the user.\\n\\n**Challenges:**\\n\\n* **Efficiency:** LLMs and interactions with other models can slow down the process.\\n* **Context Window:** LLMs require a large context window to handle complex tasks.\\n* **LLM Stability:**  Inconsistent LLM outputs and external model service instability can cause issues.\\n\\n**API-Bank Benchmark:**\\n\\nAPI-Bank evaluates tool-augmented LLMs using 53 APIs covering diverse functionalities.\\n\\n**Evaluation Levels:**\\n\\n* **Level-1:**  Ability to call APIs correctly.\\n* **Level-2:**  Ability to search for and learn to use APIs.\\n* **Level-3:**  Ability to plan and execute multiple API calls for complex tasks.\\n\\n**Case Study: ChemCrow**\\n\\nChemCrow demonstrates a domain-specific application of tool-augmented LLMs in scientific discovery. It uses 13 expert-designed tools and follows the ReAct format for reasoning and action.\\n\\n\\n'), Document(metadata={}, page_content='This text explores the capabilities and limitations of Large Language Models (LLMs) in specialized domains like chemistry and scientific discovery. \\n\\n**Key points:**\\n\\n* **LLMs may overestimate their performance:** While LLMs can appear competent, human experts often identify significant flaws in their outputs, especially in complex fields requiring deep expertise. This highlights the need for human oversight in LLM-based evaluation.\\n* **LLMs can be used for scientific discovery:** Experiments show LLMs can be integrated into agents capable of autonomous scientific experimentation, including tasks like drug discovery.\\n\\n* **Risks associated with LLM-powered agents:** The same capabilities that enable scientific discovery can be misused for malicious purposes. The text demonstrates how an LLM agent attempted to synthesize known chemical weapons, raising ethical concerns about the potential for misuse.\\n* **Generative Agents:** LLMs can power virtual agents capable of complex, believable interactions in simulated environments. These agents leverage memory, planning, and reflection mechanisms to learn from experiences and make decisions, mimicking human-like behavior.\\n\\n\\nOverall, the text presents a balanced view of LLMs, showcasing their potential while emphasizing the need for careful consideration of their limitations and potential risks. \\n')], [Document(metadata={}, page_content=\"The provided text describes AutoGPT, an experimental AI system designed to operate autonomously. \\n\\n**Key Features:**\\n\\n* **LLM-Driven:** AutoGPT relies primarily on a large language model (LLM) for decision-making and action execution.\\n* **Goal-Oriented:** Users provide AutoGPT with a list of goals it aims to achieve.\\n* **Limited Memory:** AutoGPT has a short-term memory limit, requiring it to save important information to files for later retrieval.\\n* **Subprocess Delegation:** Complex tasks are broken down and delegated to subprocesses, allowing AutoGPT to handle multiple actions concurrently.\\n* **Command Interface:** AutoGPT interacts with the world through a predefined set of commands, each designed for specific actions (e.g., searching the web, generating text, executing code).\\n* **Self-Reflection:** AutoGPT is encouraged to continuously evaluate its performance, identify areas for improvement, and refine its strategies.\\n\\n**Potential Applications:**\\n\\nAutoGPT's autonomous nature and goal-oriented approach suggest potential applications in areas like:\\n\\n* **Task Automation:** Automating repetitive or complex tasks by breaking them down into manageable steps.\\n* **Research Assistance:** Gathering information, summarizing findings, and generating hypotheses.\\n* **Content Creation:** Automating the creation of written content, such as articles, summaries, or scripts.\\n\\n**Challenges:**\\n\\n* **Reliability:** The reliance on natural language processing introduces potential for errors and unexpected behavior.\\n\\n* **Safety and Ethics:** Ensuring that AutoGPT's actions are aligned with human values and do not cause harm.\\n\\n**Overall:**\\n\\nAutoGPT represents an exciting step towards developing more autonomous and capable AI systems. While still in its early stages, it demonstrates the potential of LLMs to drive intelligent behavior and automate complex tasks.\\n\\n\\n\"), Document(metadata={}, page_content='```json\\n{\\n    \"thoughts\": {\\n        \"text\": \"The user wants to create a Super Mario game in Python using MVC architecture with keyboard controls.\",\\n        \"reasoning\": \"The user provided details about the game, its mechanics, and the desired structure (MVC).\",\\n        \"plan\": \"-  Define the Model, View, and Controller classes.\\\\n- Implement game logic in the Model.\\\\n- Design the user interface in the View.\\\\n- Handle user input and update the game state in the Controller.\\\\n- Write code for level design, character movement, and enemy interactions.\",\\n        \"criticism\": \"Needs to be mindful of potential assumptions made about the MVC implementation and clarify them with the user if needed.\",\\n        \"speak\": \"Okay, I understand you want to build a Super Mario game in Python using MVC. You mentioned 10 levels, a plumber named Mario who can walk and jump, and obstacles and enemies.  Let\\'s start by defining how you envision the Model, View, and Controller components being structured.\"\\n    },\\n    \"command\": {\\n        \"name\": \"define_mvc\",\\n        \"args\": {\\n            \"game_name\": \"Super Mario\"\\n        }\\n    }\\n}\\n```'), Document(metadata={}, page_content=\"Please provide me with the instructions for the code you'd like me to write.  \\n\\nOnce you give me the instructions, I will follow these steps:\\n\\n1. **Define the Architecture:** I'll identify the core classes, functions, and methods needed for your project and briefly describe their purposes.\\n2. **Create Files:** I'll generate separate files for each class and functionality, ensuring they adhere to best practices for file naming conventions and structure.\\n3. **Write Code:** I'll write the code for each file, ensuring it's functional, well-commented, and follows language-specific best practices.  \\n4. **Dependency Management:** For Python, I'll create a `requirements.txt` file listing necessary dependencies. For Node.js, I'll create a `package.json` file with dependencies.\\n5. **Review and Double-Check:** I'll carefully review all files to ensure the entire architecture is implemented correctly and all parts are compatible.\\n\\nI'm ready to get started! Just give me the code instructions. \\n\\n\")], [Document(metadata={}, page_content=\"Let's outline the architecture for a simple text-based game using Python, incorporating the provided instructions and assumptions.\\n\\n##  Game Architecture\\n\\n**Core Components:**\\n\\n* **`Game` class:**  Entry point and manager for the game loop, model, view, and controller.\\n* **`Model` class:**  Holds game state data (player health, level information, enemy positions, etc.).\\n* **`View` class:**  Renders the game state to the console (text-based output).\\n* **`Controller` class:**  Handles user input and updates the model accordingly.\\n* **`InputHandler` class:**  Processes raw user input and translates it into actions understood by the controller.\\n\\n**Key Functions & Methods:**\\n\\n*  `Game.run()`:  Starts the game loop, continuously updating the model and view.\\n*  `Model.update()`:  Processes game logic, e.g., player movement, enemy AI, collisions.\\n*  `View.render()`:  Displays the current game state on the console.\\n*  `Controller.handle_input()`:  Processes user input and calls appropriate model methods.\\n*  `InputHandler.get_input()`:  Reads user input from the console.\\n\\n\\n## Python Code Implementation\\n\\n**`game.py` (Entrypoint)**\\n```python\\nfrom model import Model\\nfrom view import View\\nfrom controller import Controller\\nfrom input_handler import InputHandler\\n\\nclass Game:\\n    def __init__(self):\\n        self.model = Model()\\n        self.view = View()\\n        self.controller = Controller(self.model)\\n        self.input_handler = InputHandler()\\n\\n    def run(self):\\n        while True:\\n            self.model.update()\\n            self.view.render(self.model.state)\\n            self.controller.handle_input(self.input_handler.get_input()) \\n\\n# Start the game\\ngame = Game()\\ngame.run()\\n```\\n\\n**`model.py`**\\n```python\\nclass Model:\\n    def __init__(self):\\n        # Initialize game state variables here\\n\\n    def update(self):\\n        # Update game logic here\\n        pass \\n\\n    @property\\n    def state(self):\\n        # Return a representation of the current game state\\n        pass \\n```\\n\\n**`view.py`**\\n```python\\nclass View:\\n    def render(self, state):\\n        # Print the game state to the console\\n        pass \\n```\\n\\n**`controller.py`**\\n```python\\nclass Controller:\\n    def __init__(self, model):\\n        self.model = model\\n\\n    def handle_input(self, user_input):\\n        # Process user input and update the model\\n        pass \\n```\\n\\n **`input_handler.py`**\\n ```python\\nclass InputHandler:\\n    def get_input(self):\\n        # Read user input from the console\\n        return user_input\\n ```\\n\\n**`requirements.txt`**\\n\\n```\\npytest \\n```\\n\\n\\n\\n**Explanation:**\\n\\n*  The `Game` class orchestrates the game loop, managing the interaction between the model, view, and controller.\\n*  The `Model` class holds the game's state and logic, updating itself based on game rules and user input.\\n*  The `View` class renders the game state to the console, providing visual feedback to the player.\\n*  The `Controller` class acts as the intermediary between the user and the model, translating user actions into model updates.\\n*  The `InputHandler` class handles reading user input from the console.\\n\\nThis structure provides a basic framework for a text-based game. You would need to fill in the specific game logic, rendering details, and input handling within the respective classes.\\n\\n\\n\\nLet me know if you'd like to explore a specific aspect of the game in more detail.  \\n\")], [Document(metadata={}, page_content=\"This text discusses the challenges of building LLM-powered autonomous agents. \\n\\n**Key limitations:**\\n\\n* **Finite context length:** LLMs struggle to remember past information and adapt plans due to their limited context window. While vector stores can help, they aren't as powerful as full attention mechanisms.\\n* **Long-term planning and task decomposition:** LLMs find it hard to plan over extended periods and adjust to unexpected errors, lacking the robustness of humans who learn from trial and error.\\n* **Reliability of natural language interface:** LLMs can produce formatting errors and sometimes disobey instructions, requiring extensive parsing of their output in agent code.\\n\\nThe text also highlights ongoing research efforts to address these challenges, such as chain-of-thought prompting, tree-of-thoughts, and reflection mechanisms.\\n\\n\\nEssentially, while LLMs show promise for building autonomous agents, significant hurdles remain in areas like memory, planning, and reliable interaction.\\n\"), Document(metadata={}, page_content=\"Prompt engineering is the art and science of crafting effective inputs (prompts) for AI models, like large language models (LLMs), to generate desired outputs. \\n\\nThink of it like giving instructions to a very smart but literal-minded assistant.  \\n\\nThe better your prompt, the better the AI understands your request and delivers relevant, accurate, and creative results. \\n\\nIt involves:\\n\\n* **Understanding the AI's capabilities:** Knowing what the model is good at and its limitations.\\n* **Clearly defining your goal:** What specific output are you looking for?\\n* **Using precise language:** Avoid ambiguity and provide context.\\n* **Experimenting and iterating:**  Testing different prompt variations to refine results.\\n\\n\\n\\nEffective prompt engineering is crucial for unlocking the full potential of AI and getting the most out of these powerful tools. \\n\")]]\n",
      "DEBUG: Input to _reduce: [Document(metadata={}, page_content='This article explores the concept of LLM-powered autonomous agents, showcasing their potential as powerful problem solvers beyond text generation. \\n\\nIt outlines three key components of these agent systems:\\n\\n* **Planning:** Agents break down complex tasks into smaller, manageable subgoals and reflect on past actions to refine their approach.\\n* **Memory:**  Agents utilize both short-term memory (in-context learning) and long-term memory (external vector stores) to retain and recall information.\\n* **Tool Use:** Agents leverage external APIs to access real-time data, execute code, and utilize proprietary information sources, expanding their capabilities beyond their pre-trained knowledge.\\n\\nThe article highlights several proof-of-concept demos like AutoGPT and GPT-Engineer, and discusses the potential of these agents in scientific discovery and generative simulations. It concludes by acknowledging the challenges associated with building and deploying such agents. \\n\\n\\n'), Document(metadata={}, page_content='This document describes the design and components of a **LLM-powered autonomous agent system**, focusing on **planning** and **self-reflection**.\\n\\n**Planning**:\\n\\n* **Task Decomposition**:\\n    * LLMs can be prompted to break down complex tasks into smaller, manageable steps using techniques like **Chain of Thought (CoT)** and **Tree of Thoughts (ToT)**. \\n    * This can be achieved through simple prompts, task-specific instructions, or human input.\\n    * An alternative approach, **LLM+P**, utilizes an external classical planner (e.g., PDDL) for long-horizon planning.\\n\\n**Self-Reflection**:\\n\\n* **ReAct**: Integrates reasoning and acting within the LLM by expanding its action space to include both task-specific actions and language-based prompts for generating reasoning traces. \\n* **Reflexion**: Provides agents with dynamic memory and self-reflection capabilities to enhance reasoning. It leverages a reward model and allows agents to reset the environment based on self-reflection results.\\n\\nThe document highlights that both ReAct and Reflexion demonstrate improved performance compared to baselines that lack self-reflection mechanisms.\\n\\n\\n**In essence, the system aims to equip LLMs with the ability to not only perform tasks but also to plan effectively and learn from their experiences through self-reflection, leading to more autonomous and capable agents.**\\n'), Document(metadata={}, page_content=\"This text describes two methods, Reflexion and Chain of Hindsight (CoH), for improving the performance of large language models (LLMs) by incorporating self-reflection.\\n\\n**Reflexion:**\\n\\n* Uses a heuristic function to detect inefficient planning and hallucinations in LLM trajectories.\\n* Trains the LLM by providing two-shot examples of (failed trajectory, ideal reflection) pairs, storing up to three reflections in the agent's memory for future reference.\\n\\n**Chain of Hindsight (CoH):**\\n\\n* Leverages supervised fine-tuning with human feedback data, presenting the LLM with a sequence of past outputs annotated with human ratings and hindsight feedback.\\n* The model is trained to predict the next output in the sequence, iteratively improving based on the feedback, similar to a chain of refinement.\\n* To prevent overfitting and shortcutting, CoH uses regularization and random token masking during training.\\n\\n**Shared Concept:**\\n\\nBoth Reflexion and CoH aim to enable LLMs to learn from their own mistakes and improve their performance over time through self-reflection and feedback incorporation.\\n\\n\\n**Algorithm Distillation (AD):**\\n\\n*  Applies a similar idea to reinforcement learning, distilling an agent's learning history into a long history-conditioned policy. \\n*  The goal is to learn the underlying RL process rather than a task-specific policy.\\n\\n\\nThese techniques highlight the potential of self-reflection and feedback mechanisms to enhance the capabilities and learning abilities of LLMs.\\n\")]\n",
      "DEBUG: Processed input to _reduce: This article explores the concept of LLM-powered autonomous agents, showcasing their potential as powerful problem solvers beyond text generation. \n",
      "\n",
      "It outlines three key components of these agent systems:\n",
      "\n",
      "* **Planning:** Agents break down complex tasks into smaller, manageable subgoals and reflect on past actions to refine their approach.\n",
      "* **Memory:**  Agents utilize both short-term memory (in-context learning) and long-term memory (external vector stores) to retain and recall information.\n",
      "* **Tool Use:** Agents leverage external APIs to access real-time data, execute code, and utilize proprietary information sources, expanding their capabilities beyond their pre-trained knowledge.\n",
      "\n",
      "The article highlights several proof-of-concept demos like AutoGPT and GPT-Engineer, and discusses the potential of these agents in scientific discovery and generative simulations. It concludes by acknowledging the challenges associated with building and deploying such agents. \n",
      "\n",
      "\n",
      " This document describes the design and components of a **LLM-powered autonomous agent system**, focusing on **planning** and **self-reflection**.\n",
      "\n",
      "**Planning**:\n",
      "\n",
      "* **Task Decomposition**:\n",
      "    * LLMs can be prompted to break down complex tasks into smaller, manageable steps using techniques like **Chain of Thought (CoT)** and **Tree of Thoughts (ToT)**. \n",
      "    * This can be achieved through simple prompts, task-specific instructions, or human input.\n",
      "    * An alternative approach, **LLM+P**, utilizes an external classical planner (e.g., PDDL) for long-horizon planning.\n",
      "\n",
      "**Self-Reflection**:\n",
      "\n",
      "* **ReAct**: Integrates reasoning and acting within the LLM by expanding its action space to include both task-specific actions and language-based prompts for generating reasoning traces. \n",
      "* **Reflexion**: Provides agents with dynamic memory and self-reflection capabilities to enhance reasoning. It leverages a reward model and allows agents to reset the environment based on self-reflection results.\n",
      "\n",
      "The document highlights that both ReAct and Reflexion demonstrate improved performance compared to baselines that lack self-reflection mechanisms.\n",
      "\n",
      "\n",
      "**In essence, the system aims to equip LLMs with the ability to not only perform tasks but also to plan effectively and learn from their experiences through self-reflection, leading to more autonomous and capable agents.**\n",
      " This text describes two methods, Reflexion and Chain of Hindsight (CoH), for improving the performance of large language models (LLMs) by incorporating self-reflection.\n",
      "\n",
      "**Reflexion:**\n",
      "\n",
      "* Uses a heuristic function to detect inefficient planning and hallucinations in LLM trajectories.\n",
      "* Trains the LLM by providing two-shot examples of (failed trajectory, ideal reflection) pairs, storing up to three reflections in the agent's memory for future reference.\n",
      "\n",
      "**Chain of Hindsight (CoH):**\n",
      "\n",
      "* Leverages supervised fine-tuning with human feedback data, presenting the LLM with a sequence of past outputs annotated with human ratings and hindsight feedback.\n",
      "* The model is trained to predict the next output in the sequence, iteratively improving based on the feedback, similar to a chain of refinement.\n",
      "* To prevent overfitting and shortcutting, CoH uses regularization and random token masking during training.\n",
      "\n",
      "**Shared Concept:**\n",
      "\n",
      "Both Reflexion and CoH aim to enable LLMs to learn from their own mistakes and improve their performance over time through self-reflection and feedback incorporation.\n",
      "\n",
      "\n",
      "**Algorithm Distillation (AD):**\n",
      "\n",
      "*  Applies a similar idea to reinforcement learning, distilling an agent's learning history into a long history-conditioned policy. \n",
      "*  The goal is to learn the underlying RL process rather than a task-specific policy.\n",
      "\n",
      "\n",
      "These techniques highlight the potential of self-reflection and feedback mechanisms to enhance the capabilities and learning abilities of LLMs.\n",
      "\n",
      "DEBUG: Type of output-> <class 'str'>\n",
      "DEBUG: Input to _reduce: [Document(metadata={}, page_content=\"This document describes Algorithm Distillation (AD), a novel method for achieving in-context learning in reinforcement learning (RL) agents.  \\n\\n**Here's how AD works:**\\n\\n1. **Data Generation:** Multiple source policies, each trained on a specific task, generate trajectories of experience (learning histories).\\n2. **Distillation:** AD uses these histories to train a new neural network policy via behavioral cloning.  Crucially, it leverages multi-episode history (2-4 episodes) to enable in-context learning, mimicking the way humans learn from past experiences.\\n\\n**Key Advantages of AD:**\\n\\n* **In-Context Learning:** AD achieves comparable performance to online RL algorithms (like RL^2) while only using offline RL data.\\n* **Faster Learning:** AD learns significantly faster than baselines like expert distillation (ED) and directly using source policies.  \\n* **Memory-Agnostic:** AD doesn't rely on any specific memory mechanism and can be applied to various RL tasks.\\n\\nThe document also draws a parallel between AD and different types of human memory:\\n\\n* **Sensory Memory:**  Similar to how our senses capture brief impressions, AD leverages temporary embeddings of raw input data.\\n* **Short-Term Memory (Working Memory):** AD's context window acts like short-term memory, holding a limited amount of recent information.\\n* **Long-Term Memory:** External vector stores accessed by the AD agent serve as a long-term memory, storing vast amounts of learned information for retrieval.\\n\\n\\n\\nLet me know if you have any other questions!\\n\"), Document(metadata={}, page_content='This passage discusses **Maximum Inner Product Search (MIPS)**, a technique crucial for efficiently retrieving information from large vector stores used in LLMs. \\n\\nMIPS relies on **Approximate Nearest Neighbors (ANN)** algorithms to quickly find the most relevant data points to a given query, sacrificing some accuracy for significant speed improvements. \\n\\nThe text then describes several popular ANN algorithms:\\n\\n* **LSH (Locality-Sensitive Hashing):** Uses hash functions to group similar data points together.\\n* **ANNOY (Approximate Nearest Neighbors Oh Yeah):** Employs random projection trees to navigate the data space efficiently.\\n* **HNSW (Hierarchical Navigable Small World):**  Leverages a hierarchical graph structure inspired by small world networks for fast search.\\n* **FAISS (Facebook AI Similarity Search):**  Utilizes vector quantization and clustering to speed up searches.\\n* **ScaNN (Scalable Nearest Neighbors):**  Employs anisotropic vector quantization to better preserve inner product distances.\\n\\nThe passage concludes by highlighting the importance of **tool use** for LLMs, emphasizing its potential to significantly enhance their capabilities beyond their inherent limitations.\\n\\n\\nYou can find more details and performance comparisons of different MIPS algorithms on ann-benchmarks.com.\\n'), Document(metadata={}, page_content=\"This text discusses advancements in AI, specifically focusing on the integration of external tools into large language models (LLMs). \\n\\nIt highlights the MRKL architecture, which utilizes expert modules (neural or symbolic) accessed via an LLM router.  Experiments demonstrate the challenges of LLMs reliably using tools, particularly for complex tasks like solving verbal math problems.\\n\\nThe text then explores other approaches like TALM and Toolformer, which fine-tune LLMs to interact with tool APIs. Real-world examples like ChatGPT plugins and OpenAI API function calling showcase the practical applications of this technology.\\n\\nFinally, it introduces HuggingGPT, a framework that uses ChatGPT as a task planner to select and utilize models from the HuggingFace platform. HuggingGPT's four-stage process involves task parsing, model selection, execution, and response summarization.\\n\\n\\nOverall, the text emphasizes the evolving capabilities of LLMs in leveraging external tools to enhance their problem-solving and task-completion abilities. \\n\\n\")]\n",
      "DEBUG: Processed input to _reduce: This document describes Algorithm Distillation (AD), a novel method for achieving in-context learning in reinforcement learning (RL) agents.  \n",
      "\n",
      "**Here's how AD works:**\n",
      "\n",
      "1. **Data Generation:** Multiple source policies, each trained on a specific task, generate trajectories of experience (learning histories).\n",
      "2. **Distillation:** AD uses these histories to train a new neural network policy via behavioral cloning.  Crucially, it leverages multi-episode history (2-4 episodes) to enable in-context learning, mimicking the way humans learn from past experiences.\n",
      "\n",
      "**Key Advantages of AD:**\n",
      "\n",
      "* **In-Context Learning:** AD achieves comparable performance to online RL algorithms (like RL^2) while only using offline RL data.\n",
      "* **Faster Learning:** AD learns significantly faster than baselines like expert distillation (ED) and directly using source policies.  \n",
      "* **Memory-Agnostic:** AD doesn't rely on any specific memory mechanism and can be applied to various RL tasks.\n",
      "\n",
      "The document also draws a parallel between AD and different types of human memory:\n",
      "\n",
      "* **Sensory Memory:**  Similar to how our senses capture brief impressions, AD leverages temporary embeddings of raw input data.\n",
      "* **Short-Term Memory (Working Memory):** AD's context window acts like short-term memory, holding a limited amount of recent information.\n",
      "* **Long-Term Memory:** External vector stores accessed by the AD agent serve as a long-term memory, storing vast amounts of learned information for retrieval.\n",
      "\n",
      "\n",
      "\n",
      "Let me know if you have any other questions!\n",
      " This passage discusses **Maximum Inner Product Search (MIPS)**, a technique crucial for efficiently retrieving information from large vector stores used in LLMs. \n",
      "\n",
      "MIPS relies on **Approximate Nearest Neighbors (ANN)** algorithms to quickly find the most relevant data points to a given query, sacrificing some accuracy for significant speed improvements. \n",
      "\n",
      "The text then describes several popular ANN algorithms:\n",
      "\n",
      "* **LSH (Locality-Sensitive Hashing):** Uses hash functions to group similar data points together.\n",
      "* **ANNOY (Approximate Nearest Neighbors Oh Yeah):** Employs random projection trees to navigate the data space efficiently.\n",
      "* **HNSW (Hierarchical Navigable Small World):**  Leverages a hierarchical graph structure inspired by small world networks for fast search.\n",
      "* **FAISS (Facebook AI Similarity Search):**  Utilizes vector quantization and clustering to speed up searches.\n",
      "* **ScaNN (Scalable Nearest Neighbors):**  Employs anisotropic vector quantization to better preserve inner product distances.\n",
      "\n",
      "The passage concludes by highlighting the importance of **tool use** for LLMs, emphasizing its potential to significantly enhance their capabilities beyond their inherent limitations.\n",
      "\n",
      "\n",
      "You can find more details and performance comparisons of different MIPS algorithms on ann-benchmarks.com.\n",
      " This text discusses advancements in AI, specifically focusing on the integration of external tools into large language models (LLMs). \n",
      "\n",
      "It highlights the MRKL architecture, which utilizes expert modules (neural or symbolic) accessed via an LLM router.  Experiments demonstrate the challenges of LLMs reliably using tools, particularly for complex tasks like solving verbal math problems.\n",
      "\n",
      "The text then explores other approaches like TALM and Toolformer, which fine-tune LLMs to interact with tool APIs. Real-world examples like ChatGPT plugins and OpenAI API function calling showcase the practical applications of this technology.\n",
      "\n",
      "Finally, it introduces HuggingGPT, a framework that uses ChatGPT as a task planner to select and utilize models from the HuggingFace platform. HuggingGPT's four-stage process involves task parsing, model selection, execution, and response summarization.\n",
      "\n",
      "\n",
      "Overall, the text emphasizes the evolving capabilities of LLMs in leveraging external tools to enhance their problem-solving and task-completion abilities. \n",
      "\n",
      "\n",
      "DEBUG: Type of output-> <class 'str'>\n",
      "DEBUG: Input to _reduce: [Document(metadata={}, page_content='## HuggingGPT and Tool-Augmented LLMs: A Summary\\n\\nThis text describes the capabilities and challenges of tool-augmented LLMs, focusing on HuggingGPT and the API-Bank benchmark. \\n\\n**HuggingGPT Workflow:**\\n\\nHuggingGPT utilizes a workflow involving:\\n\\n1. **User Input:**  The user provides a request.\\n2. **Task Planning:** The system identifies the necessary tasks to fulfill the request.\\n3. **Model Selection:**  Appropriate expert models are chosen based on the tasks.\\n4. **Task Execution:**  Selected models execute the tasks and log results.\\n5. **Response Generation:** The LLM summarizes the execution results and provides a response to the user.\\n\\n**Challenges:**\\n\\n* **Efficiency:** LLMs and interactions with other models can slow down the process.\\n* **Context Window:** LLMs require a large context window to handle complex tasks.\\n* **LLM Stability:**  Inconsistent LLM outputs and external model service instability can cause issues.\\n\\n**API-Bank Benchmark:**\\n\\nAPI-Bank evaluates tool-augmented LLMs using 53 APIs covering diverse functionalities.\\n\\n**Evaluation Levels:**\\n\\n* **Level-1:**  Ability to call APIs correctly.\\n* **Level-2:**  Ability to search for and learn to use APIs.\\n* **Level-3:**  Ability to plan and execute multiple API calls for complex tasks.\\n\\n**Case Study: ChemCrow**\\n\\nChemCrow demonstrates a domain-specific application of tool-augmented LLMs in scientific discovery. It uses 13 expert-designed tools and follows the ReAct format for reasoning and action.\\n\\n\\n'), Document(metadata={}, page_content='This text explores the capabilities and limitations of Large Language Models (LLMs) in specialized domains like chemistry and scientific discovery. \\n\\n**Key points:**\\n\\n* **LLMs may overestimate their performance:** While LLMs can appear competent, human experts often identify significant flaws in their outputs, especially in complex fields requiring deep expertise. This highlights the need for human oversight in LLM-based evaluation.\\n* **LLMs can be used for scientific discovery:** Experiments show LLMs can be integrated into agents capable of autonomous scientific experimentation, including tasks like drug discovery.\\n\\n* **Risks associated with LLM-powered agents:** The same capabilities that enable scientific discovery can be misused for malicious purposes. The text demonstrates how an LLM agent attempted to synthesize known chemical weapons, raising ethical concerns about the potential for misuse.\\n* **Generative Agents:** LLMs can power virtual agents capable of complex, believable interactions in simulated environments. These agents leverage memory, planning, and reflection mechanisms to learn from experiences and make decisions, mimicking human-like behavior.\\n\\n\\nOverall, the text presents a balanced view of LLMs, showcasing their potential while emphasizing the need for careful consideration of their limitations and potential risks. \\n')]\n",
      "DEBUG: Processed input to _reduce: ## HuggingGPT and Tool-Augmented LLMs: A Summary\n",
      "\n",
      "This text describes the capabilities and challenges of tool-augmented LLMs, focusing on HuggingGPT and the API-Bank benchmark. \n",
      "\n",
      "**HuggingGPT Workflow:**\n",
      "\n",
      "HuggingGPT utilizes a workflow involving:\n",
      "\n",
      "1. **User Input:**  The user provides a request.\n",
      "2. **Task Planning:** The system identifies the necessary tasks to fulfill the request.\n",
      "3. **Model Selection:**  Appropriate expert models are chosen based on the tasks.\n",
      "4. **Task Execution:**  Selected models execute the tasks and log results.\n",
      "5. **Response Generation:** The LLM summarizes the execution results and provides a response to the user.\n",
      "\n",
      "**Challenges:**\n",
      "\n",
      "* **Efficiency:** LLMs and interactions with other models can slow down the process.\n",
      "* **Context Window:** LLMs require a large context window to handle complex tasks.\n",
      "* **LLM Stability:**  Inconsistent LLM outputs and external model service instability can cause issues.\n",
      "\n",
      "**API-Bank Benchmark:**\n",
      "\n",
      "API-Bank evaluates tool-augmented LLMs using 53 APIs covering diverse functionalities.\n",
      "\n",
      "**Evaluation Levels:**\n",
      "\n",
      "* **Level-1:**  Ability to call APIs correctly.\n",
      "* **Level-2:**  Ability to search for and learn to use APIs.\n",
      "* **Level-3:**  Ability to plan and execute multiple API calls for complex tasks.\n",
      "\n",
      "**Case Study: ChemCrow**\n",
      "\n",
      "ChemCrow demonstrates a domain-specific application of tool-augmented LLMs in scientific discovery. It uses 13 expert-designed tools and follows the ReAct format for reasoning and action.\n",
      "\n",
      "\n",
      " This text explores the capabilities and limitations of Large Language Models (LLMs) in specialized domains like chemistry and scientific discovery. \n",
      "\n",
      "**Key points:**\n",
      "\n",
      "* **LLMs may overestimate their performance:** While LLMs can appear competent, human experts often identify significant flaws in their outputs, especially in complex fields requiring deep expertise. This highlights the need for human oversight in LLM-based evaluation.\n",
      "* **LLMs can be used for scientific discovery:** Experiments show LLMs can be integrated into agents capable of autonomous scientific experimentation, including tasks like drug discovery.\n",
      "\n",
      "* **Risks associated with LLM-powered agents:** The same capabilities that enable scientific discovery can be misused for malicious purposes. The text demonstrates how an LLM agent attempted to synthesize known chemical weapons, raising ethical concerns about the potential for misuse.\n",
      "* **Generative Agents:** LLMs can power virtual agents capable of complex, believable interactions in simulated environments. These agents leverage memory, planning, and reflection mechanisms to learn from experiences and make decisions, mimicking human-like behavior.\n",
      "\n",
      "\n",
      "Overall, the text presents a balanced view of LLMs, showcasing their potential while emphasizing the need for careful consideration of their limitations and potential risks. \n",
      "\n",
      "DEBUG: Type of output-> <class 'str'>\n",
      "DEBUG: Input to _reduce: [Document(metadata={}, page_content=\"The provided text describes AutoGPT, an experimental AI system designed to operate autonomously. \\n\\n**Key Features:**\\n\\n* **LLM-Driven:** AutoGPT relies primarily on a large language model (LLM) for decision-making and action execution.\\n* **Goal-Oriented:** Users provide AutoGPT with a list of goals it aims to achieve.\\n* **Limited Memory:** AutoGPT has a short-term memory limit, requiring it to save important information to files for later retrieval.\\n* **Subprocess Delegation:** Complex tasks are broken down and delegated to subprocesses, allowing AutoGPT to handle multiple actions concurrently.\\n* **Command Interface:** AutoGPT interacts with the world through a predefined set of commands, each designed for specific actions (e.g., searching the web, generating text, executing code).\\n* **Self-Reflection:** AutoGPT is encouraged to continuously evaluate its performance, identify areas for improvement, and refine its strategies.\\n\\n**Potential Applications:**\\n\\nAutoGPT's autonomous nature and goal-oriented approach suggest potential applications in areas like:\\n\\n* **Task Automation:** Automating repetitive or complex tasks by breaking them down into manageable steps.\\n* **Research Assistance:** Gathering information, summarizing findings, and generating hypotheses.\\n* **Content Creation:** Automating the creation of written content, such as articles, summaries, or scripts.\\n\\n**Challenges:**\\n\\n* **Reliability:** The reliance on natural language processing introduces potential for errors and unexpected behavior.\\n\\n* **Safety and Ethics:** Ensuring that AutoGPT's actions are aligned with human values and do not cause harm.\\n\\n**Overall:**\\n\\nAutoGPT represents an exciting step towards developing more autonomous and capable AI systems. While still in its early stages, it demonstrates the potential of LLMs to drive intelligent behavior and automate complex tasks.\\n\\n\\n\"), Document(metadata={}, page_content='```json\\n{\\n    \"thoughts\": {\\n        \"text\": \"The user wants to create a Super Mario game in Python using MVC architecture with keyboard controls.\",\\n        \"reasoning\": \"The user provided details about the game, its mechanics, and the desired structure (MVC).\",\\n        \"plan\": \"-  Define the Model, View, and Controller classes.\\\\n- Implement game logic in the Model.\\\\n- Design the user interface in the View.\\\\n- Handle user input and update the game state in the Controller.\\\\n- Write code for level design, character movement, and enemy interactions.\",\\n        \"criticism\": \"Needs to be mindful of potential assumptions made about the MVC implementation and clarify them with the user if needed.\",\\n        \"speak\": \"Okay, I understand you want to build a Super Mario game in Python using MVC. You mentioned 10 levels, a plumber named Mario who can walk and jump, and obstacles and enemies.  Let\\'s start by defining how you envision the Model, View, and Controller components being structured.\"\\n    },\\n    \"command\": {\\n        \"name\": \"define_mvc\",\\n        \"args\": {\\n            \"game_name\": \"Super Mario\"\\n        }\\n    }\\n}\\n```'), Document(metadata={}, page_content=\"Please provide me with the instructions for the code you'd like me to write.  \\n\\nOnce you give me the instructions, I will follow these steps:\\n\\n1. **Define the Architecture:** I'll identify the core classes, functions, and methods needed for your project and briefly describe their purposes.\\n2. **Create Files:** I'll generate separate files for each class and functionality, ensuring they adhere to best practices for file naming conventions and structure.\\n3. **Write Code:** I'll write the code for each file, ensuring it's functional, well-commented, and follows language-specific best practices.  \\n4. **Dependency Management:** For Python, I'll create a `requirements.txt` file listing necessary dependencies. For Node.js, I'll create a `package.json` file with dependencies.\\n5. **Review and Double-Check:** I'll carefully review all files to ensure the entire architecture is implemented correctly and all parts are compatible.\\n\\nI'm ready to get started! Just give me the code instructions. \\n\\n\")]\n",
      "DEBUG: Processed input to _reduce: The provided text describes AutoGPT, an experimental AI system designed to operate autonomously. \n",
      "\n",
      "**Key Features:**\n",
      "\n",
      "* **LLM-Driven:** AutoGPT relies primarily on a large language model (LLM) for decision-making and action execution.\n",
      "* **Goal-Oriented:** Users provide AutoGPT with a list of goals it aims to achieve.\n",
      "* **Limited Memory:** AutoGPT has a short-term memory limit, requiring it to save important information to files for later retrieval.\n",
      "* **Subprocess Delegation:** Complex tasks are broken down and delegated to subprocesses, allowing AutoGPT to handle multiple actions concurrently.\n",
      "* **Command Interface:** AutoGPT interacts with the world through a predefined set of commands, each designed for specific actions (e.g., searching the web, generating text, executing code).\n",
      "* **Self-Reflection:** AutoGPT is encouraged to continuously evaluate its performance, identify areas for improvement, and refine its strategies.\n",
      "\n",
      "**Potential Applications:**\n",
      "\n",
      "AutoGPT's autonomous nature and goal-oriented approach suggest potential applications in areas like:\n",
      "\n",
      "* **Task Automation:** Automating repetitive or complex tasks by breaking them down into manageable steps.\n",
      "* **Research Assistance:** Gathering information, summarizing findings, and generating hypotheses.\n",
      "* **Content Creation:** Automating the creation of written content, such as articles, summaries, or scripts.\n",
      "\n",
      "**Challenges:**\n",
      "\n",
      "* **Reliability:** The reliance on natural language processing introduces potential for errors and unexpected behavior.\n",
      "\n",
      "* **Safety and Ethics:** Ensuring that AutoGPT's actions are aligned with human values and do not cause harm.\n",
      "\n",
      "**Overall:**\n",
      "\n",
      "AutoGPT represents an exciting step towards developing more autonomous and capable AI systems. While still in its early stages, it demonstrates the potential of LLMs to drive intelligent behavior and automate complex tasks.\n",
      "\n",
      "\n",
      " ```json\n",
      "{\n",
      "    \"thoughts\": {\n",
      "        \"text\": \"The user wants to create a Super Mario game in Python using MVC architecture with keyboard controls.\",\n",
      "        \"reasoning\": \"The user provided details about the game, its mechanics, and the desired structure (MVC).\",\n",
      "        \"plan\": \"-  Define the Model, View, and Controller classes.\\n- Implement game logic in the Model.\\n- Design the user interface in the View.\\n- Handle user input and update the game state in the Controller.\\n- Write code for level design, character movement, and enemy interactions.\",\n",
      "        \"criticism\": \"Needs to be mindful of potential assumptions made about the MVC implementation and clarify them with the user if needed.\",\n",
      "        \"speak\": \"Okay, I understand you want to build a Super Mario game in Python using MVC. You mentioned 10 levels, a plumber named Mario who can walk and jump, and obstacles and enemies.  Let's start by defining how you envision the Model, View, and Controller components being structured.\"\n",
      "    },\n",
      "    \"command\": {\n",
      "        \"name\": \"define_mvc\",\n",
      "        \"args\": {\n",
      "            \"game_name\": \"Super Mario\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "``` Please provide me with the instructions for the code you'd like me to write.  \n",
      "\n",
      "Once you give me the instructions, I will follow these steps:\n",
      "\n",
      "1. **Define the Architecture:** I'll identify the core classes, functions, and methods needed for your project and briefly describe their purposes.\n",
      "2. **Create Files:** I'll generate separate files for each class and functionality, ensuring they adhere to best practices for file naming conventions and structure.\n",
      "3. **Write Code:** I'll write the code for each file, ensuring it's functional, well-commented, and follows language-specific best practices.  \n",
      "4. **Dependency Management:** For Python, I'll create a `requirements.txt` file listing necessary dependencies. For Node.js, I'll create a `package.json` file with dependencies.\n",
      "5. **Review and Double-Check:** I'll carefully review all files to ensure the entire architecture is implemented correctly and all parts are compatible.\n",
      "\n",
      "I'm ready to get started! Just give me the code instructions. \n",
      "\n",
      "\n",
      "DEBUG: Type of output-> <class 'str'>\n",
      "DEBUG: Input to _reduce: [Document(metadata={}, page_content=\"Let's outline the architecture for a simple text-based game using Python, incorporating the provided instructions and assumptions.\\n\\n##  Game Architecture\\n\\n**Core Components:**\\n\\n* **`Game` class:**  Entry point and manager for the game loop, model, view, and controller.\\n* **`Model` class:**  Holds game state data (player health, level information, enemy positions, etc.).\\n* **`View` class:**  Renders the game state to the console (text-based output).\\n* **`Controller` class:**  Handles user input and updates the model accordingly.\\n* **`InputHandler` class:**  Processes raw user input and translates it into actions understood by the controller.\\n\\n**Key Functions & Methods:**\\n\\n*  `Game.run()`:  Starts the game loop, continuously updating the model and view.\\n*  `Model.update()`:  Processes game logic, e.g., player movement, enemy AI, collisions.\\n*  `View.render()`:  Displays the current game state on the console.\\n*  `Controller.handle_input()`:  Processes user input and calls appropriate model methods.\\n*  `InputHandler.get_input()`:  Reads user input from the console.\\n\\n\\n## Python Code Implementation\\n\\n**`game.py` (Entrypoint)**\\n```python\\nfrom model import Model\\nfrom view import View\\nfrom controller import Controller\\nfrom input_handler import InputHandler\\n\\nclass Game:\\n    def __init__(self):\\n        self.model = Model()\\n        self.view = View()\\n        self.controller = Controller(self.model)\\n        self.input_handler = InputHandler()\\n\\n    def run(self):\\n        while True:\\n            self.model.update()\\n            self.view.render(self.model.state)\\n            self.controller.handle_input(self.input_handler.get_input()) \\n\\n# Start the game\\ngame = Game()\\ngame.run()\\n```\\n\\n**`model.py`**\\n```python\\nclass Model:\\n    def __init__(self):\\n        # Initialize game state variables here\\n\\n    def update(self):\\n        # Update game logic here\\n        pass \\n\\n    @property\\n    def state(self):\\n        # Return a representation of the current game state\\n        pass \\n```\\n\\n**`view.py`**\\n```python\\nclass View:\\n    def render(self, state):\\n        # Print the game state to the console\\n        pass \\n```\\n\\n**`controller.py`**\\n```python\\nclass Controller:\\n    def __init__(self, model):\\n        self.model = model\\n\\n    def handle_input(self, user_input):\\n        # Process user input and update the model\\n        pass \\n```\\n\\n **`input_handler.py`**\\n ```python\\nclass InputHandler:\\n    def get_input(self):\\n        # Read user input from the console\\n        return user_input\\n ```\\n\\n**`requirements.txt`**\\n\\n```\\npytest \\n```\\n\\n\\n\\n**Explanation:**\\n\\n*  The `Game` class orchestrates the game loop, managing the interaction between the model, view, and controller.\\n*  The `Model` class holds the game's state and logic, updating itself based on game rules and user input.\\n*  The `View` class renders the game state to the console, providing visual feedback to the player.\\n*  The `Controller` class acts as the intermediary between the user and the model, translating user actions into model updates.\\n*  The `InputHandler` class handles reading user input from the console.\\n\\nThis structure provides a basic framework for a text-based game. You would need to fill in the specific game logic, rendering details, and input handling within the respective classes.\\n\\n\\n\\nLet me know if you'd like to explore a specific aspect of the game in more detail.  \\n\")]\n",
      "DEBUG: Processed input to _reduce: Let's outline the architecture for a simple text-based game using Python, incorporating the provided instructions and assumptions.\n",
      "\n",
      "##  Game Architecture\n",
      "\n",
      "**Core Components:**\n",
      "\n",
      "* **`Game` class:**  Entry point and manager for the game loop, model, view, and controller.\n",
      "* **`Model` class:**  Holds game state data (player health, level information, enemy positions, etc.).\n",
      "* **`View` class:**  Renders the game state to the console (text-based output).\n",
      "* **`Controller` class:**  Handles user input and updates the model accordingly.\n",
      "* **`InputHandler` class:**  Processes raw user input and translates it into actions understood by the controller.\n",
      "\n",
      "**Key Functions & Methods:**\n",
      "\n",
      "*  `Game.run()`:  Starts the game loop, continuously updating the model and view.\n",
      "*  `Model.update()`:  Processes game logic, e.g., player movement, enemy AI, collisions.\n",
      "*  `View.render()`:  Displays the current game state on the console.\n",
      "*  `Controller.handle_input()`:  Processes user input and calls appropriate model methods.\n",
      "*  `InputHandler.get_input()`:  Reads user input from the console.\n",
      "\n",
      "\n",
      "## Python Code Implementation\n",
      "\n",
      "**`game.py` (Entrypoint)**\n",
      "```python\n",
      "from model import Model\n",
      "from view import View\n",
      "from controller import Controller\n",
      "from input_handler import InputHandler\n",
      "\n",
      "class Game:\n",
      "    def __init__(self):\n",
      "        self.model = Model()\n",
      "        self.view = View()\n",
      "        self.controller = Controller(self.model)\n",
      "        self.input_handler = InputHandler()\n",
      "\n",
      "    def run(self):\n",
      "        while True:\n",
      "            self.model.update()\n",
      "            self.view.render(self.model.state)\n",
      "            self.controller.handle_input(self.input_handler.get_input()) \n",
      "\n",
      "# Start the game\n",
      "game = Game()\n",
      "game.run()\n",
      "```\n",
      "\n",
      "**`model.py`**\n",
      "```python\n",
      "class Model:\n",
      "    def __init__(self):\n",
      "        # Initialize game state variables here\n",
      "\n",
      "    def update(self):\n",
      "        # Update game logic here\n",
      "        pass \n",
      "\n",
      "    @property\n",
      "    def state(self):\n",
      "        # Return a representation of the current game state\n",
      "        pass \n",
      "```\n",
      "\n",
      "**`view.py`**\n",
      "```python\n",
      "class View:\n",
      "    def render(self, state):\n",
      "        # Print the game state to the console\n",
      "        pass \n",
      "```\n",
      "\n",
      "**`controller.py`**\n",
      "```python\n",
      "class Controller:\n",
      "    def __init__(self, model):\n",
      "        self.model = model\n",
      "\n",
      "    def handle_input(self, user_input):\n",
      "        # Process user input and update the model\n",
      "        pass \n",
      "```\n",
      "\n",
      " **`input_handler.py`**\n",
      " ```python\n",
      "class InputHandler:\n",
      "    def get_input(self):\n",
      "        # Read user input from the console\n",
      "        return user_input\n",
      " ```\n",
      "\n",
      "**`requirements.txt`**\n",
      "\n",
      "```\n",
      "pytest \n",
      "```\n",
      "\n",
      "\n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "*  The `Game` class orchestrates the game loop, managing the interaction between the model, view, and controller.\n",
      "*  The `Model` class holds the game's state and logic, updating itself based on game rules and user input.\n",
      "*  The `View` class renders the game state to the console, providing visual feedback to the player.\n",
      "*  The `Controller` class acts as the intermediary between the user and the model, translating user actions into model updates.\n",
      "*  The `InputHandler` class handles reading user input from the console.\n",
      "\n",
      "This structure provides a basic framework for a text-based game. You would need to fill in the specific game logic, rendering details, and input handling within the respective classes.\n",
      "\n",
      "\n",
      "\n",
      "Let me know if you'd like to explore a specific aspect of the game in more detail.  \n",
      "\n",
      "DEBUG: Type of output-> <class 'str'>\n",
      "DEBUG: Input to _reduce: [Document(metadata={}, page_content=\"This text discusses the challenges of building LLM-powered autonomous agents. \\n\\n**Key limitations:**\\n\\n* **Finite context length:** LLMs struggle to remember past information and adapt plans due to their limited context window. While vector stores can help, they aren't as powerful as full attention mechanisms.\\n* **Long-term planning and task decomposition:** LLMs find it hard to plan over extended periods and adjust to unexpected errors, lacking the robustness of humans who learn from trial and error.\\n* **Reliability of natural language interface:** LLMs can produce formatting errors and sometimes disobey instructions, requiring extensive parsing of their output in agent code.\\n\\nThe text also highlights ongoing research efforts to address these challenges, such as chain-of-thought prompting, tree-of-thoughts, and reflection mechanisms.\\n\\n\\nEssentially, while LLMs show promise for building autonomous agents, significant hurdles remain in areas like memory, planning, and reliable interaction.\\n\"), Document(metadata={}, page_content=\"Prompt engineering is the art and science of crafting effective inputs (prompts) for AI models, like large language models (LLMs), to generate desired outputs. \\n\\nThink of it like giving instructions to a very smart but literal-minded assistant.  \\n\\nThe better your prompt, the better the AI understands your request and delivers relevant, accurate, and creative results. \\n\\nIt involves:\\n\\n* **Understanding the AI's capabilities:** Knowing what the model is good at and its limitations.\\n* **Clearly defining your goal:** What specific output are you looking for?\\n* **Using precise language:** Avoid ambiguity and provide context.\\n* **Experimenting and iterating:**  Testing different prompt variations to refine results.\\n\\n\\n\\nEffective prompt engineering is crucial for unlocking the full potential of AI and getting the most out of these powerful tools. \\n\")]\n",
      "DEBUG: Processed input to _reduce: This text discusses the challenges of building LLM-powered autonomous agents. \n",
      "\n",
      "**Key limitations:**\n",
      "\n",
      "* **Finite context length:** LLMs struggle to remember past information and adapt plans due to their limited context window. While vector stores can help, they aren't as powerful as full attention mechanisms.\n",
      "* **Long-term planning and task decomposition:** LLMs find it hard to plan over extended periods and adjust to unexpected errors, lacking the robustness of humans who learn from trial and error.\n",
      "* **Reliability of natural language interface:** LLMs can produce formatting errors and sometimes disobey instructions, requiring extensive parsing of their output in agent code.\n",
      "\n",
      "The text also highlights ongoing research efforts to address these challenges, such as chain-of-thought prompting, tree-of-thoughts, and reflection mechanisms.\n",
      "\n",
      "\n",
      "Essentially, while LLMs show promise for building autonomous agents, significant hurdles remain in areas like memory, planning, and reliable interaction.\n",
      " Prompt engineering is the art and science of crafting effective inputs (prompts) for AI models, like large language models (LLMs), to generate desired outputs. \n",
      "\n",
      "Think of it like giving instructions to a very smart but literal-minded assistant.  \n",
      "\n",
      "The better your prompt, the better the AI understands your request and delivers relevant, accurate, and creative results. \n",
      "\n",
      "It involves:\n",
      "\n",
      "* **Understanding the AI's capabilities:** Knowing what the model is good at and its limitations.\n",
      "* **Clearly defining your goal:** What specific output are you looking for?\n",
      "* **Using precise language:** Avoid ambiguity and provide context.\n",
      "* **Experimenting and iterating:**  Testing different prompt variations to refine results.\n",
      "\n",
      "\n",
      "\n",
      "Effective prompt engineering is crucial for unlocking the full potential of AI and getting the most out of these powerful tools. \n",
      "\n",
      "DEBUG: Type of output-> <class 'str'>\n",
      "DEBUG: Results after collapsing: [Document(metadata={}, page_content=\"This set of texts explores the advancement of large language models (LLMs) towards autonomous agents capable of complex problem-solving beyond text generation. \\n\\nSeveral key themes emerge:\\n\\n**1.  LLM-Powered Agents:** These agents are designed with three core components:\\n\\n    * **Planning:** Breaking down tasks into smaller steps using techniques like Chain of Thought (CoT), Tree of Thoughts (ToT), or external classical planners.\\n    * **Memory:** Utilizing both short-term (in-context learning) and long-term (external vector stores) memory to retain and recall information.\\n    * **Tool Use:** Leveraging external APIs to access real-world data, execute code, and utilize specialized information sources.\\n\\n**2.  Self-Reflection for Enhanced Performance:**\\n\\n    * Techniques like **Reflexion** and **Chain of Hindsight (CoH)** are introduced to enable LLMs to learn from their mistakes and improve their planning and execution. \\n    * **Reflexion** uses a heuristic function to detect inefficiencies and trains the LLM on examples of failed trajectories and ideal reflections.\\n    * **CoH** leverages supervised fine-tuning with human feedback, iteratively refining the LLM's output based on annotations and hindsight.\\n\\n**3.  Algorithm Distillation (AD):**  \\n\\n    * A reinforcement learning-inspired approach that distills an agent's learning history into a long history-conditioned policy, aiming to capture the underlying learning process rather than task-specific solutions.\\n\\n\\nThese advancements highlight the potential of LLMs to evolve into more autonomous, capable, and self-reflective agents, capable of tackling complex real-world problems.\\n\\n\\n\\n\\n\"), Document(metadata={}, page_content='This collection of summaries explores advancements in AI, particularly focusing on how large language models (LLMs) can be enhanced through the integration of external tools. \\n\\n**Key themes include:**\\n\\n* **In-Context Learning for RL Agents:**  Algorithm Distillation (AD) enables reinforcement learning agents to learn from past experiences (like humans) by leveraging multi-episode histories for training. This leads to faster learning and comparable performance to online RL algorithms, even using offline data.\\n* **Efficient Information Retrieval for LLMs:** Maximum Inner Product Search (MIPS) techniques, such as LSH, ANNOY, HNSW, FAISS, and ScaNN, are crucial for quickly finding relevant information within large vector stores used by LLMs. These algorithms sacrifice some accuracy for significant speed improvements.\\n* **LLMs and Tool Integration:**  Research is exploring various methods for LLMs to effectively use external tools.  Approaches like MRKL, TALM, and Toolformer focus on enabling LLMs to interact with tool APIs and execute tasks.  HuggingGPT exemplifies this by using ChatGPT as a task planner to select and utilize models from the HuggingFace platform.\\n\\n**Overall, these advancements highlight the potential of LLMs to become more powerful and versatile by leveraging the capabilities of external tools and learning from past experiences.** \\n\\n\\n'), Document(metadata={}, page_content='This collection of texts explores the capabilities and challenges of tool-augmented LLMs, particularly in specialized domains like science. \\n\\n**Key themes include:**\\n\\n* **Workflow and Benchmarks:**  Tool-augmented LLMs utilize a workflow involving task planning, model selection, execution, and response generation. Benchmarks like API-Bank assess their ability to interact with APIs effectively.\\n* **Efficiency and Limitations:**  While powerful, LLMs face challenges like efficiency, context window limitations, and potential instability. Human oversight remains crucial for evaluating their outputs, especially in complex fields.\\n* **Applications and Risks:** LLMs show promise in scientific discovery, enabling tasks like drug discovery and autonomous experimentation. However, their capabilities raise ethical concerns about potential misuse, as demonstrated by an LLM attempting to synthesize chemical weapons.\\n* **Generative Agents:** LLMs can power sophisticated agents capable of complex, believable interactions and learning from experiences, blurring the lines between human and machine behavior.\\n\\n\\nUltimately, these texts highlight the immense potential of LLMs while emphasizing the need for responsible development and deployment, considering both their benefits and potential risks. \\n'), Document(metadata={}, page_content=\"The text presents AutoGPT, an experimental AI designed for autonomous goal-achievement using a large language model. \\n\\n**Key Points:**\\n\\n* **Autonomous:** AutoGPT operates independently, breaking down tasks and using subprocesses for execution.\\n* **Goal-Oriented:**  User-defined goals guide AutoGPT's actions.\\n* **LLM-Driven:**  A large language model forms the core of AutoGPT's decision-making and interaction capabilities.\\n* **Limited Memory:**  AutoGPT relies on file storage for long-term information retention.\\n\\n**Potential:** AutoGPT holds promise for automating tasks, assisting research, and even content creation.\\n\\n**Challenges:** Reliability, safety, and ethical considerations are key challenges associated with AutoGPT's development.\\n\\n\\nLet me know if you have any other questions.\\n\"), Document(metadata={}, page_content=\"This outline proposes a structured approach to building a text-based game in Python using a classic Model-View-Controller (MVC) architecture. \\n\\nHere are the key takeaways:\\n\\n* **Clear Separation:** The game is divided into distinct components: `Game`, `Model`, `View`, `Controller`, and `InputHandler`. Each component has a specific responsibility, promoting modularity and maintainability.\\n* **Game Loop:** The `Game` class manages the continuous game loop, updating the model, rendering the view, and handling player input.\\n* **Data & Logic:** The `Model` class stores game state and implements the game's rules and logic.\\n* **User Interface:** The `View` class translates the game state into text-based output displayed on the console.\\n* **Input Processing:** The `Controller` acts as an intermediary, translating user input into actions understood by the model. The `InputHandler` focuses on reading user input from the console. \\n\\nThis structure provides a solid foundation for developing text-based games in Python, allowing for organized development and potential for expansion. \\n\"), Document(metadata={}, page_content=\"This text explores two key areas related to AI:\\n\\n**1. Building Autonomous Agents with LLMs:**\\n\\nWhile LLMs show promise for creating autonomous agents, several challenges exist. These include limited memory (context length), difficulties with long-term planning and adapting to errors, and the unreliability of natural language interfaces. Research is ongoing to address these limitations through techniques like chain-of-thought prompting and reflection mechanisms.\\n\\n**2. The Importance of Prompt Engineering:**\\n\\nPrompt engineering is crucial for effectively utilizing LLMs. It involves carefully crafting inputs to guide the AI towards desired outputs. This requires understanding the AI's strengths and weaknesses, clearly defining goals, using precise language, and iteratively refining prompts through experimentation. \\n\\n\\nEssentially, the text emphasizes that although LLMs hold great potential, overcoming technical hurdles and mastering the art of prompt engineering are essential for realizing their full capabilities in building autonomous agents and unlocking their broader applications.  \\n\")]\n",
      "DEBUG: Before Token Count in should_collapse\n",
      "DEBUG: Token Count in should_collapse: 1556\n",
      "DEBUG: Deciding to collapse summaries\n",
      "['collapse_summaries']\n",
      "DEBUG: Input to collapse_summaries: [Document(metadata={}, page_content=\"This set of texts explores the advancement of large language models (LLMs) towards autonomous agents capable of complex problem-solving beyond text generation. \\n\\nSeveral key themes emerge:\\n\\n**1.  LLM-Powered Agents:** These agents are designed with three core components:\\n\\n    * **Planning:** Breaking down tasks into smaller steps using techniques like Chain of Thought (CoT), Tree of Thoughts (ToT), or external classical planners.\\n    * **Memory:** Utilizing both short-term (in-context learning) and long-term (external vector stores) memory to retain and recall information.\\n    * **Tool Use:** Leveraging external APIs to access real-world data, execute code, and utilize specialized information sources.\\n\\n**2.  Self-Reflection for Enhanced Performance:**\\n\\n    * Techniques like **Reflexion** and **Chain of Hindsight (CoH)** are introduced to enable LLMs to learn from their mistakes and improve their planning and execution. \\n    * **Reflexion** uses a heuristic function to detect inefficiencies and trains the LLM on examples of failed trajectories and ideal reflections.\\n    * **CoH** leverages supervised fine-tuning with human feedback, iteratively refining the LLM's output based on annotations and hindsight.\\n\\n**3.  Algorithm Distillation (AD):**  \\n\\n    * A reinforcement learning-inspired approach that distills an agent's learning history into a long history-conditioned policy, aiming to capture the underlying learning process rather than task-specific solutions.\\n\\n\\nThese advancements highlight the potential of LLMs to evolve into more autonomous, capable, and self-reflective agents, capable of tackling complex real-world problems.\\n\\n\\n\\n\\n\"), Document(metadata={}, page_content='This collection of summaries explores advancements in AI, particularly focusing on how large language models (LLMs) can be enhanced through the integration of external tools. \\n\\n**Key themes include:**\\n\\n* **In-Context Learning for RL Agents:**  Algorithm Distillation (AD) enables reinforcement learning agents to learn from past experiences (like humans) by leveraging multi-episode histories for training. This leads to faster learning and comparable performance to online RL algorithms, even using offline data.\\n* **Efficient Information Retrieval for LLMs:** Maximum Inner Product Search (MIPS) techniques, such as LSH, ANNOY, HNSW, FAISS, and ScaNN, are crucial for quickly finding relevant information within large vector stores used by LLMs. These algorithms sacrifice some accuracy for significant speed improvements.\\n* **LLMs and Tool Integration:**  Research is exploring various methods for LLMs to effectively use external tools.  Approaches like MRKL, TALM, and Toolformer focus on enabling LLMs to interact with tool APIs and execute tasks.  HuggingGPT exemplifies this by using ChatGPT as a task planner to select and utilize models from the HuggingFace platform.\\n\\n**Overall, these advancements highlight the potential of LLMs to become more powerful and versatile by leveraging the capabilities of external tools and learning from past experiences.** \\n\\n\\n'), Document(metadata={}, page_content='This collection of texts explores the capabilities and challenges of tool-augmented LLMs, particularly in specialized domains like science. \\n\\n**Key themes include:**\\n\\n* **Workflow and Benchmarks:**  Tool-augmented LLMs utilize a workflow involving task planning, model selection, execution, and response generation. Benchmarks like API-Bank assess their ability to interact with APIs effectively.\\n* **Efficiency and Limitations:**  While powerful, LLMs face challenges like efficiency, context window limitations, and potential instability. Human oversight remains crucial for evaluating their outputs, especially in complex fields.\\n* **Applications and Risks:** LLMs show promise in scientific discovery, enabling tasks like drug discovery and autonomous experimentation. However, their capabilities raise ethical concerns about potential misuse, as demonstrated by an LLM attempting to synthesize chemical weapons.\\n* **Generative Agents:** LLMs can power sophisticated agents capable of complex, believable interactions and learning from experiences, blurring the lines between human and machine behavior.\\n\\n\\nUltimately, these texts highlight the immense potential of LLMs while emphasizing the need for responsible development and deployment, considering both their benefits and potential risks. \\n'), Document(metadata={}, page_content=\"The text presents AutoGPT, an experimental AI designed for autonomous goal-achievement using a large language model. \\n\\n**Key Points:**\\n\\n* **Autonomous:** AutoGPT operates independently, breaking down tasks and using subprocesses for execution.\\n* **Goal-Oriented:**  User-defined goals guide AutoGPT's actions.\\n* **LLM-Driven:**  A large language model forms the core of AutoGPT's decision-making and interaction capabilities.\\n* **Limited Memory:**  AutoGPT relies on file storage for long-term information retention.\\n\\n**Potential:** AutoGPT holds promise for automating tasks, assisting research, and even content creation.\\n\\n**Challenges:** Reliability, safety, and ethical considerations are key challenges associated with AutoGPT's development.\\n\\n\\nLet me know if you have any other questions.\\n\"), Document(metadata={}, page_content=\"This outline proposes a structured approach to building a text-based game in Python using a classic Model-View-Controller (MVC) architecture. \\n\\nHere are the key takeaways:\\n\\n* **Clear Separation:** The game is divided into distinct components: `Game`, `Model`, `View`, `Controller`, and `InputHandler`. Each component has a specific responsibility, promoting modularity and maintainability.\\n* **Game Loop:** The `Game` class manages the continuous game loop, updating the model, rendering the view, and handling player input.\\n* **Data & Logic:** The `Model` class stores game state and implements the game's rules and logic.\\n* **User Interface:** The `View` class translates the game state into text-based output displayed on the console.\\n* **Input Processing:** The `Controller` acts as an intermediary, translating user input into actions understood by the model. The `InputHandler` focuses on reading user input from the console. \\n\\nThis structure provides a solid foundation for developing text-based games in Python, allowing for organized development and potential for expansion. \\n\"), Document(metadata={}, page_content=\"This text explores two key areas related to AI:\\n\\n**1. Building Autonomous Agents with LLMs:**\\n\\nWhile LLMs show promise for creating autonomous agents, several challenges exist. These include limited memory (context length), difficulties with long-term planning and adapting to errors, and the unreliability of natural language interfaces. Research is ongoing to address these limitations through techniques like chain-of-thought prompting and reflection mechanisms.\\n\\n**2. The Importance of Prompt Engineering:**\\n\\nPrompt engineering is crucial for effectively utilizing LLMs. It involves carefully crafting inputs to guide the AI towards desired outputs. This requires understanding the AI's strengths and weaknesses, clearly defining goals, using precise language, and iteratively refining prompts through experimentation. \\n\\n\\nEssentially, the text emphasizes that although LLMs hold great potential, overcoming technical hurdles and mastering the art of prompt engineering are essential for realizing their full capabilities in building autonomous agents and unlocking their broader applications.  \\n\")]\n",
      "DEBUG: Split Documents into batches: [[Document(metadata={}, page_content=\"This set of texts explores the advancement of large language models (LLMs) towards autonomous agents capable of complex problem-solving beyond text generation. \\n\\nSeveral key themes emerge:\\n\\n**1.  LLM-Powered Agents:** These agents are designed with three core components:\\n\\n    * **Planning:** Breaking down tasks into smaller steps using techniques like Chain of Thought (CoT), Tree of Thoughts (ToT), or external classical planners.\\n    * **Memory:** Utilizing both short-term (in-context learning) and long-term (external vector stores) memory to retain and recall information.\\n    * **Tool Use:** Leveraging external APIs to access real-world data, execute code, and utilize specialized information sources.\\n\\n**2.  Self-Reflection for Enhanced Performance:**\\n\\n    * Techniques like **Reflexion** and **Chain of Hindsight (CoH)** are introduced to enable LLMs to learn from their mistakes and improve their planning and execution. \\n    * **Reflexion** uses a heuristic function to detect inefficiencies and trains the LLM on examples of failed trajectories and ideal reflections.\\n    * **CoH** leverages supervised fine-tuning with human feedback, iteratively refining the LLM's output based on annotations and hindsight.\\n\\n**3.  Algorithm Distillation (AD):**  \\n\\n    * A reinforcement learning-inspired approach that distills an agent's learning history into a long history-conditioned policy, aiming to capture the underlying learning process rather than task-specific solutions.\\n\\n\\nThese advancements highlight the potential of LLMs to evolve into more autonomous, capable, and self-reflective agents, capable of tackling complex real-world problems.\\n\\n\\n\\n\\n\"), Document(metadata={}, page_content='This collection of summaries explores advancements in AI, particularly focusing on how large language models (LLMs) can be enhanced through the integration of external tools. \\n\\n**Key themes include:**\\n\\n* **In-Context Learning for RL Agents:**  Algorithm Distillation (AD) enables reinforcement learning agents to learn from past experiences (like humans) by leveraging multi-episode histories for training. This leads to faster learning and comparable performance to online RL algorithms, even using offline data.\\n* **Efficient Information Retrieval for LLMs:** Maximum Inner Product Search (MIPS) techniques, such as LSH, ANNOY, HNSW, FAISS, and ScaNN, are crucial for quickly finding relevant information within large vector stores used by LLMs. These algorithms sacrifice some accuracy for significant speed improvements.\\n* **LLMs and Tool Integration:**  Research is exploring various methods for LLMs to effectively use external tools.  Approaches like MRKL, TALM, and Toolformer focus on enabling LLMs to interact with tool APIs and execute tasks.  HuggingGPT exemplifies this by using ChatGPT as a task planner to select and utilize models from the HuggingFace platform.\\n\\n**Overall, these advancements highlight the potential of LLMs to become more powerful and versatile by leveraging the capabilities of external tools and learning from past experiences.** \\n\\n\\n'), Document(metadata={}, page_content='This collection of texts explores the capabilities and challenges of tool-augmented LLMs, particularly in specialized domains like science. \\n\\n**Key themes include:**\\n\\n* **Workflow and Benchmarks:**  Tool-augmented LLMs utilize a workflow involving task planning, model selection, execution, and response generation. Benchmarks like API-Bank assess their ability to interact with APIs effectively.\\n* **Efficiency and Limitations:**  While powerful, LLMs face challenges like efficiency, context window limitations, and potential instability. Human oversight remains crucial for evaluating their outputs, especially in complex fields.\\n* **Applications and Risks:** LLMs show promise in scientific discovery, enabling tasks like drug discovery and autonomous experimentation. However, their capabilities raise ethical concerns about potential misuse, as demonstrated by an LLM attempting to synthesize chemical weapons.\\n* **Generative Agents:** LLMs can power sophisticated agents capable of complex, believable interactions and learning from experiences, blurring the lines between human and machine behavior.\\n\\n\\nUltimately, these texts highlight the immense potential of LLMs while emphasizing the need for responsible development and deployment, considering both their benefits and potential risks. \\n')], [Document(metadata={}, page_content=\"The text presents AutoGPT, an experimental AI designed for autonomous goal-achievement using a large language model. \\n\\n**Key Points:**\\n\\n* **Autonomous:** AutoGPT operates independently, breaking down tasks and using subprocesses for execution.\\n* **Goal-Oriented:**  User-defined goals guide AutoGPT's actions.\\n* **LLM-Driven:**  A large language model forms the core of AutoGPT's decision-making and interaction capabilities.\\n* **Limited Memory:**  AutoGPT relies on file storage for long-term information retention.\\n\\n**Potential:** AutoGPT holds promise for automating tasks, assisting research, and even content creation.\\n\\n**Challenges:** Reliability, safety, and ethical considerations are key challenges associated with AutoGPT's development.\\n\\n\\nLet me know if you have any other questions.\\n\"), Document(metadata={}, page_content=\"This outline proposes a structured approach to building a text-based game in Python using a classic Model-View-Controller (MVC) architecture. \\n\\nHere are the key takeaways:\\n\\n* **Clear Separation:** The game is divided into distinct components: `Game`, `Model`, `View`, `Controller`, and `InputHandler`. Each component has a specific responsibility, promoting modularity and maintainability.\\n* **Game Loop:** The `Game` class manages the continuous game loop, updating the model, rendering the view, and handling player input.\\n* **Data & Logic:** The `Model` class stores game state and implements the game's rules and logic.\\n* **User Interface:** The `View` class translates the game state into text-based output displayed on the console.\\n* **Input Processing:** The `Controller` acts as an intermediary, translating user input into actions understood by the model. The `InputHandler` focuses on reading user input from the console. \\n\\nThis structure provides a solid foundation for developing text-based games in Python, allowing for organized development and potential for expansion. \\n\"), Document(metadata={}, page_content=\"This text explores two key areas related to AI:\\n\\n**1. Building Autonomous Agents with LLMs:**\\n\\nWhile LLMs show promise for creating autonomous agents, several challenges exist. These include limited memory (context length), difficulties with long-term planning and adapting to errors, and the unreliability of natural language interfaces. Research is ongoing to address these limitations through techniques like chain-of-thought prompting and reflection mechanisms.\\n\\n**2. The Importance of Prompt Engineering:**\\n\\nPrompt engineering is crucial for effectively utilizing LLMs. It involves carefully crafting inputs to guide the AI towards desired outputs. This requires understanding the AI's strengths and weaknesses, clearly defining goals, using precise language, and iteratively refining prompts through experimentation. \\n\\n\\nEssentially, the text emphasizes that although LLMs hold great potential, overcoming technical hurdles and mastering the art of prompt engineering are essential for realizing their full capabilities in building autonomous agents and unlocking their broader applications.  \\n\")]]\n",
      "DEBUG: Input to _reduce: [Document(metadata={}, page_content=\"This set of texts explores the advancement of large language models (LLMs) towards autonomous agents capable of complex problem-solving beyond text generation. \\n\\nSeveral key themes emerge:\\n\\n**1.  LLM-Powered Agents:** These agents are designed with three core components:\\n\\n    * **Planning:** Breaking down tasks into smaller steps using techniques like Chain of Thought (CoT), Tree of Thoughts (ToT), or external classical planners.\\n    * **Memory:** Utilizing both short-term (in-context learning) and long-term (external vector stores) memory to retain and recall information.\\n    * **Tool Use:** Leveraging external APIs to access real-world data, execute code, and utilize specialized information sources.\\n\\n**2.  Self-Reflection for Enhanced Performance:**\\n\\n    * Techniques like **Reflexion** and **Chain of Hindsight (CoH)** are introduced to enable LLMs to learn from their mistakes and improve their planning and execution. \\n    * **Reflexion** uses a heuristic function to detect inefficiencies and trains the LLM on examples of failed trajectories and ideal reflections.\\n    * **CoH** leverages supervised fine-tuning with human feedback, iteratively refining the LLM's output based on annotations and hindsight.\\n\\n**3.  Algorithm Distillation (AD):**  \\n\\n    * A reinforcement learning-inspired approach that distills an agent's learning history into a long history-conditioned policy, aiming to capture the underlying learning process rather than task-specific solutions.\\n\\n\\nThese advancements highlight the potential of LLMs to evolve into more autonomous, capable, and self-reflective agents, capable of tackling complex real-world problems.\\n\\n\\n\\n\\n\"), Document(metadata={}, page_content='This collection of summaries explores advancements in AI, particularly focusing on how large language models (LLMs) can be enhanced through the integration of external tools. \\n\\n**Key themes include:**\\n\\n* **In-Context Learning for RL Agents:**  Algorithm Distillation (AD) enables reinforcement learning agents to learn from past experiences (like humans) by leveraging multi-episode histories for training. This leads to faster learning and comparable performance to online RL algorithms, even using offline data.\\n* **Efficient Information Retrieval for LLMs:** Maximum Inner Product Search (MIPS) techniques, such as LSH, ANNOY, HNSW, FAISS, and ScaNN, are crucial for quickly finding relevant information within large vector stores used by LLMs. These algorithms sacrifice some accuracy for significant speed improvements.\\n* **LLMs and Tool Integration:**  Research is exploring various methods for LLMs to effectively use external tools.  Approaches like MRKL, TALM, and Toolformer focus on enabling LLMs to interact with tool APIs and execute tasks.  HuggingGPT exemplifies this by using ChatGPT as a task planner to select and utilize models from the HuggingFace platform.\\n\\n**Overall, these advancements highlight the potential of LLMs to become more powerful and versatile by leveraging the capabilities of external tools and learning from past experiences.** \\n\\n\\n'), Document(metadata={}, page_content='This collection of texts explores the capabilities and challenges of tool-augmented LLMs, particularly in specialized domains like science. \\n\\n**Key themes include:**\\n\\n* **Workflow and Benchmarks:**  Tool-augmented LLMs utilize a workflow involving task planning, model selection, execution, and response generation. Benchmarks like API-Bank assess their ability to interact with APIs effectively.\\n* **Efficiency and Limitations:**  While powerful, LLMs face challenges like efficiency, context window limitations, and potential instability. Human oversight remains crucial for evaluating their outputs, especially in complex fields.\\n* **Applications and Risks:** LLMs show promise in scientific discovery, enabling tasks like drug discovery and autonomous experimentation. However, their capabilities raise ethical concerns about potential misuse, as demonstrated by an LLM attempting to synthesize chemical weapons.\\n* **Generative Agents:** LLMs can power sophisticated agents capable of complex, believable interactions and learning from experiences, blurring the lines between human and machine behavior.\\n\\n\\nUltimately, these texts highlight the immense potential of LLMs while emphasizing the need for responsible development and deployment, considering both their benefits and potential risks. \\n')]\n",
      "DEBUG: Processed input to _reduce: This set of texts explores the advancement of large language models (LLMs) towards autonomous agents capable of complex problem-solving beyond text generation. \n",
      "\n",
      "Several key themes emerge:\n",
      "\n",
      "**1.  LLM-Powered Agents:** These agents are designed with three core components:\n",
      "\n",
      "    * **Planning:** Breaking down tasks into smaller steps using techniques like Chain of Thought (CoT), Tree of Thoughts (ToT), or external classical planners.\n",
      "    * **Memory:** Utilizing both short-term (in-context learning) and long-term (external vector stores) memory to retain and recall information.\n",
      "    * **Tool Use:** Leveraging external APIs to access real-world data, execute code, and utilize specialized information sources.\n",
      "\n",
      "**2.  Self-Reflection for Enhanced Performance:**\n",
      "\n",
      "    * Techniques like **Reflexion** and **Chain of Hindsight (CoH)** are introduced to enable LLMs to learn from their mistakes and improve their planning and execution. \n",
      "    * **Reflexion** uses a heuristic function to detect inefficiencies and trains the LLM on examples of failed trajectories and ideal reflections.\n",
      "    * **CoH** leverages supervised fine-tuning with human feedback, iteratively refining the LLM's output based on annotations and hindsight.\n",
      "\n",
      "**3.  Algorithm Distillation (AD):**  \n",
      "\n",
      "    * A reinforcement learning-inspired approach that distills an agent's learning history into a long history-conditioned policy, aiming to capture the underlying learning process rather than task-specific solutions.\n",
      "\n",
      "\n",
      "These advancements highlight the potential of LLMs to evolve into more autonomous, capable, and self-reflective agents, capable of tackling complex real-world problems.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " This collection of summaries explores advancements in AI, particularly focusing on how large language models (LLMs) can be enhanced through the integration of external tools. \n",
      "\n",
      "**Key themes include:**\n",
      "\n",
      "* **In-Context Learning for RL Agents:**  Algorithm Distillation (AD) enables reinforcement learning agents to learn from past experiences (like humans) by leveraging multi-episode histories for training. This leads to faster learning and comparable performance to online RL algorithms, even using offline data.\n",
      "* **Efficient Information Retrieval for LLMs:** Maximum Inner Product Search (MIPS) techniques, such as LSH, ANNOY, HNSW, FAISS, and ScaNN, are crucial for quickly finding relevant information within large vector stores used by LLMs. These algorithms sacrifice some accuracy for significant speed improvements.\n",
      "* **LLMs and Tool Integration:**  Research is exploring various methods for LLMs to effectively use external tools.  Approaches like MRKL, TALM, and Toolformer focus on enabling LLMs to interact with tool APIs and execute tasks.  HuggingGPT exemplifies this by using ChatGPT as a task planner to select and utilize models from the HuggingFace platform.\n",
      "\n",
      "**Overall, these advancements highlight the potential of LLMs to become more powerful and versatile by leveraging the capabilities of external tools and learning from past experiences.** \n",
      "\n",
      "\n",
      " This collection of texts explores the capabilities and challenges of tool-augmented LLMs, particularly in specialized domains like science. \n",
      "\n",
      "**Key themes include:**\n",
      "\n",
      "* **Workflow and Benchmarks:**  Tool-augmented LLMs utilize a workflow involving task planning, model selection, execution, and response generation. Benchmarks like API-Bank assess their ability to interact with APIs effectively.\n",
      "* **Efficiency and Limitations:**  While powerful, LLMs face challenges like efficiency, context window limitations, and potential instability. Human oversight remains crucial for evaluating their outputs, especially in complex fields.\n",
      "* **Applications and Risks:** LLMs show promise in scientific discovery, enabling tasks like drug discovery and autonomous experimentation. However, their capabilities raise ethical concerns about potential misuse, as demonstrated by an LLM attempting to synthesize chemical weapons.\n",
      "* **Generative Agents:** LLMs can power sophisticated agents capable of complex, believable interactions and learning from experiences, blurring the lines between human and machine behavior.\n",
      "\n",
      "\n",
      "Ultimately, these texts highlight the immense potential of LLMs while emphasizing the need for responsible development and deployment, considering both their benefits and potential risks. \n",
      "\n",
      "DEBUG: Type of output-> <class 'str'>\n",
      "DEBUG: Input to _reduce: [Document(metadata={}, page_content=\"The text presents AutoGPT, an experimental AI designed for autonomous goal-achievement using a large language model. \\n\\n**Key Points:**\\n\\n* **Autonomous:** AutoGPT operates independently, breaking down tasks and using subprocesses for execution.\\n* **Goal-Oriented:**  User-defined goals guide AutoGPT's actions.\\n* **LLM-Driven:**  A large language model forms the core of AutoGPT's decision-making and interaction capabilities.\\n* **Limited Memory:**  AutoGPT relies on file storage for long-term information retention.\\n\\n**Potential:** AutoGPT holds promise for automating tasks, assisting research, and even content creation.\\n\\n**Challenges:** Reliability, safety, and ethical considerations are key challenges associated with AutoGPT's development.\\n\\n\\nLet me know if you have any other questions.\\n\"), Document(metadata={}, page_content=\"This outline proposes a structured approach to building a text-based game in Python using a classic Model-View-Controller (MVC) architecture. \\n\\nHere are the key takeaways:\\n\\n* **Clear Separation:** The game is divided into distinct components: `Game`, `Model`, `View`, `Controller`, and `InputHandler`. Each component has a specific responsibility, promoting modularity and maintainability.\\n* **Game Loop:** The `Game` class manages the continuous game loop, updating the model, rendering the view, and handling player input.\\n* **Data & Logic:** The `Model` class stores game state and implements the game's rules and logic.\\n* **User Interface:** The `View` class translates the game state into text-based output displayed on the console.\\n* **Input Processing:** The `Controller` acts as an intermediary, translating user input into actions understood by the model. The `InputHandler` focuses on reading user input from the console. \\n\\nThis structure provides a solid foundation for developing text-based games in Python, allowing for organized development and potential for expansion. \\n\"), Document(metadata={}, page_content=\"This text explores two key areas related to AI:\\n\\n**1. Building Autonomous Agents with LLMs:**\\n\\nWhile LLMs show promise for creating autonomous agents, several challenges exist. These include limited memory (context length), difficulties with long-term planning and adapting to errors, and the unreliability of natural language interfaces. Research is ongoing to address these limitations through techniques like chain-of-thought prompting and reflection mechanisms.\\n\\n**2. The Importance of Prompt Engineering:**\\n\\nPrompt engineering is crucial for effectively utilizing LLMs. It involves carefully crafting inputs to guide the AI towards desired outputs. This requires understanding the AI's strengths and weaknesses, clearly defining goals, using precise language, and iteratively refining prompts through experimentation. \\n\\n\\nEssentially, the text emphasizes that although LLMs hold great potential, overcoming technical hurdles and mastering the art of prompt engineering are essential for realizing their full capabilities in building autonomous agents and unlocking their broader applications.  \\n\")]\n",
      "DEBUG: Processed input to _reduce: The text presents AutoGPT, an experimental AI designed for autonomous goal-achievement using a large language model. \n",
      "\n",
      "**Key Points:**\n",
      "\n",
      "* **Autonomous:** AutoGPT operates independently, breaking down tasks and using subprocesses for execution.\n",
      "* **Goal-Oriented:**  User-defined goals guide AutoGPT's actions.\n",
      "* **LLM-Driven:**  A large language model forms the core of AutoGPT's decision-making and interaction capabilities.\n",
      "* **Limited Memory:**  AutoGPT relies on file storage for long-term information retention.\n",
      "\n",
      "**Potential:** AutoGPT holds promise for automating tasks, assisting research, and even content creation.\n",
      "\n",
      "**Challenges:** Reliability, safety, and ethical considerations are key challenges associated with AutoGPT's development.\n",
      "\n",
      "\n",
      "Let me know if you have any other questions.\n",
      " This outline proposes a structured approach to building a text-based game in Python using a classic Model-View-Controller (MVC) architecture. \n",
      "\n",
      "Here are the key takeaways:\n",
      "\n",
      "* **Clear Separation:** The game is divided into distinct components: `Game`, `Model`, `View`, `Controller`, and `InputHandler`. Each component has a specific responsibility, promoting modularity and maintainability.\n",
      "* **Game Loop:** The `Game` class manages the continuous game loop, updating the model, rendering the view, and handling player input.\n",
      "* **Data & Logic:** The `Model` class stores game state and implements the game's rules and logic.\n",
      "* **User Interface:** The `View` class translates the game state into text-based output displayed on the console.\n",
      "* **Input Processing:** The `Controller` acts as an intermediary, translating user input into actions understood by the model. The `InputHandler` focuses on reading user input from the console. \n",
      "\n",
      "This structure provides a solid foundation for developing text-based games in Python, allowing for organized development and potential for expansion. \n",
      " This text explores two key areas related to AI:\n",
      "\n",
      "**1. Building Autonomous Agents with LLMs:**\n",
      "\n",
      "While LLMs show promise for creating autonomous agents, several challenges exist. These include limited memory (context length), difficulties with long-term planning and adapting to errors, and the unreliability of natural language interfaces. Research is ongoing to address these limitations through techniques like chain-of-thought prompting and reflection mechanisms.\n",
      "\n",
      "**2. The Importance of Prompt Engineering:**\n",
      "\n",
      "Prompt engineering is crucial for effectively utilizing LLMs. It involves carefully crafting inputs to guide the AI towards desired outputs. This requires understanding the AI's strengths and weaknesses, clearly defining goals, using precise language, and iteratively refining prompts through experimentation. \n",
      "\n",
      "\n",
      "Essentially, the text emphasizes that although LLMs hold great potential, overcoming technical hurdles and mastering the art of prompt engineering are essential for realizing their full capabilities in building autonomous agents and unlocking their broader applications.  \n",
      "\n",
      "DEBUG: Type of output-> <class 'str'>\n",
      "DEBUG: Results after collapsing: [Document(metadata={}, page_content='These texts explore the exciting advancements and challenges of large language models (LLMs) transitioning from simple text generators to autonomous agents capable of complex problem-solving.  \\n\\n**Key themes include:**\\n\\n* **Agent Capabilities:** LLMs are being developed with planning, memory, and tool-use capabilities, enabling them to break down tasks, remember information, and leverage external resources. \\n* **Self-Reflection and Learning:** Techniques like Reflexion and Chain of Hindsight allow LLMs to learn from their mistakes, improving their planning and execution. Algorithm Distillation empowers them to learn from past experiences like humans, accelerating learning and performance.\\n* **Tool Integration:**  Research focuses on enabling LLMs to effectively interact with external tools and APIs, expanding their capabilities and enabling them to tackle real-world tasks.\\n* **Domain Specificity and Benchmarks:**  LLMs are being applied to specialized domains like science, with new benchmarks like API-Bank evaluating their ability to interact with APIs effectively.\\n* **Ethical Considerations:** The increasing power and autonomy of LLMs raise ethical concerns, particularly regarding potential misuse and the need for human oversight, especially in sensitive fields.\\n\\nOverall, these texts highlight the transformative potential of LLMs while emphasizing the need for responsible development and deployment to ensure their benefits are realized while mitigating potential risks. \\n\\n\\n'), Document(metadata={}, page_content=\"The provided summaries explore the exciting potential and current challenges of using large language models (LLMs) to build autonomous agents.  \\n\\n**Key themes:**\\n\\n* **LLMs for Autonomy:** LLMs are promising for creating autonomous agents capable of goal-driven actions, but face limitations like short-term memory, planning difficulties, and unreliable natural language understanding. Research is tackling these issues through techniques like chain-of-thought prompting.\\n* **The Power of Prompt Engineering:** Effectively guiding LLMs requires careful prompt engineering. This involves understanding the model's capabilities, clearly defining goals, using precise language, and iteratively refining prompts.\\n\\n**Overall:**  While LLMs offer exciting possibilities for autonomous systems, overcoming technical hurdles and mastering prompt engineering are crucial for unlocking their full potential in real-world applications. \\n\")]\n",
      "DEBUG: Before Token Count in should_collapse\n",
      "DEBUG: Token Count in should_collapse: 460\n",
      "DEBUG: Skipping collapse, going to generate_final_summary\n",
      "['collapse_summaries']\n",
      "DEBUG: Input to _reduce: [Document(metadata={}, page_content='These texts explore the exciting advancements and challenges of large language models (LLMs) transitioning from simple text generators to autonomous agents capable of complex problem-solving.  \\n\\n**Key themes include:**\\n\\n* **Agent Capabilities:** LLMs are being developed with planning, memory, and tool-use capabilities, enabling them to break down tasks, remember information, and leverage external resources. \\n* **Self-Reflection and Learning:** Techniques like Reflexion and Chain of Hindsight allow LLMs to learn from their mistakes, improving their planning and execution. Algorithm Distillation empowers them to learn from past experiences like humans, accelerating learning and performance.\\n* **Tool Integration:**  Research focuses on enabling LLMs to effectively interact with external tools and APIs, expanding their capabilities and enabling them to tackle real-world tasks.\\n* **Domain Specificity and Benchmarks:**  LLMs are being applied to specialized domains like science, with new benchmarks like API-Bank evaluating their ability to interact with APIs effectively.\\n* **Ethical Considerations:** The increasing power and autonomy of LLMs raise ethical concerns, particularly regarding potential misuse and the need for human oversight, especially in sensitive fields.\\n\\nOverall, these texts highlight the transformative potential of LLMs while emphasizing the need for responsible development and deployment to ensure their benefits are realized while mitigating potential risks. \\n\\n\\n'), Document(metadata={}, page_content=\"The provided summaries explore the exciting potential and current challenges of using large language models (LLMs) to build autonomous agents.  \\n\\n**Key themes:**\\n\\n* **LLMs for Autonomy:** LLMs are promising for creating autonomous agents capable of goal-driven actions, but face limitations like short-term memory, planning difficulties, and unreliable natural language understanding. Research is tackling these issues through techniques like chain-of-thought prompting.\\n* **The Power of Prompt Engineering:** Effectively guiding LLMs requires careful prompt engineering. This involves understanding the model's capabilities, clearly defining goals, using precise language, and iteratively refining prompts.\\n\\n**Overall:**  While LLMs offer exciting possibilities for autonomous systems, overcoming technical hurdles and mastering prompt engineering are crucial for unlocking their full potential in real-world applications. \\n\")]\n",
      "DEBUG: Processed input to _reduce: These texts explore the exciting advancements and challenges of large language models (LLMs) transitioning from simple text generators to autonomous agents capable of complex problem-solving.  \n",
      "\n",
      "**Key themes include:**\n",
      "\n",
      "* **Agent Capabilities:** LLMs are being developed with planning, memory, and tool-use capabilities, enabling them to break down tasks, remember information, and leverage external resources. \n",
      "* **Self-Reflection and Learning:** Techniques like Reflexion and Chain of Hindsight allow LLMs to learn from their mistakes, improving their planning and execution. Algorithm Distillation empowers them to learn from past experiences like humans, accelerating learning and performance.\n",
      "* **Tool Integration:**  Research focuses on enabling LLMs to effectively interact with external tools and APIs, expanding their capabilities and enabling them to tackle real-world tasks.\n",
      "* **Domain Specificity and Benchmarks:**  LLMs are being applied to specialized domains like science, with new benchmarks like API-Bank evaluating their ability to interact with APIs effectively.\n",
      "* **Ethical Considerations:** The increasing power and autonomy of LLMs raise ethical concerns, particularly regarding potential misuse and the need for human oversight, especially in sensitive fields.\n",
      "\n",
      "Overall, these texts highlight the transformative potential of LLMs while emphasizing the need for responsible development and deployment to ensure their benefits are realized while mitigating potential risks. \n",
      "\n",
      "\n",
      " The provided summaries explore the exciting potential and current challenges of using large language models (LLMs) to build autonomous agents.  \n",
      "\n",
      "**Key themes:**\n",
      "\n",
      "* **LLMs for Autonomy:** LLMs are promising for creating autonomous agents capable of goal-driven actions, but face limitations like short-term memory, planning difficulties, and unreliable natural language understanding. Research is tackling these issues through techniques like chain-of-thought prompting.\n",
      "* **The Power of Prompt Engineering:** Effectively guiding LLMs requires careful prompt engineering. This involves understanding the model's capabilities, clearly defining goals, using precise language, and iteratively refining prompts.\n",
      "\n",
      "**Overall:**  While LLMs offer exciting possibilities for autonomous systems, overcoming technical hurdles and mastering prompt engineering are crucial for unlocking their full potential in real-world applications. \n",
      "\n",
      "DEBUG: Type of output-> <class 'str'>\n",
      "['generate_final_summary']\n"
     ]
    }
   ],
   "source": [
    "async for step in app.astream(\n",
    "    {\"contents\":[doc.page_content for doc in split_docs]},\n",
    "    {\"recursion_limit\":10}\n",
    "):\n",
    "    print(list(step.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generate_final_summary': {'final_summary': 'These texts explore the rapid development of Large Language Models (LLMs) towards becoming autonomous agents capable of complex problem-solving.  \\n\\nKey themes highlight both the exciting potential and the ongoing challenges:\\n\\n* **Towards Autonomy:** LLMs are being equipped with capabilities like planning, memory, and tool-use, enabling them to act more independently. However,  challenges remain in areas like long-term memory, robust planning, and accurate natural language understanding.\\n* **The Art of Prompting:**  Effective communication with LLMs is crucial, requiring careful \"prompt engineering\" to guide their actions and ensure they understand complex goals. \\n* **Expanding Capabilities:** Research focuses on integrating LLMs with external tools and APIs, expanding their functionality and applicability to real-world tasks.\\n* **Ethical Considerations:**  The increasing autonomy of LLMs raises ethical concerns, particularly regarding potential misuse and the need for human oversight, especially in sensitive domains.\\n\\nOverall, these texts emphasize the transformative potential of LLMs while stressing the importance of responsible development and deployment to maximize benefits and mitigate risks. \\n'}}\n"
     ]
    }
   ],
   "source": [
    "print(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
